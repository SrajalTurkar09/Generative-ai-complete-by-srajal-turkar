{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "LfT4OI48IkOt",
        "outputId": "73bacc7c-bd94-42c6-b91d-f6b1c221f014"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Greedy Decoding Result: cat sat on the mat\n",
            "Beam Search Decoding Result: cat sat on the mat\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Vocabulary of words\n",
        "vocabulary = np.array([\"The\", \"cat\", \"sat\", \"on\", \"the\", \"mat\", \"in\", \"sun\"])\n",
        "\n",
        "# Dummy probability distributions for each step (rows are steps, columns correspond to vocabulary words)\n",
        "# These probabilities simulate a language model trying to form a meaningful sentence\n",
        "probabilities = np.array([\n",
        "    [0.2, 0.6, 0.05, 0.05, 0.05, 0.05, 0.0, 0.0],  # After \"The\", \"cat\" is likely\n",
        "    [0.1, 0.1, 0.6, 0.1, 0.05, 0.05, 0.0, 0.0],    # After \"cat\", \"sat\" is likely\n",
        "    [0.05, 0.1, 0.1, 0.5, 0.2, 0.05, 0.0, 0.0],    # After \"sat\", \"on\" is likely\n",
        "    [0.05, 0.1, 0.1, 0.1, 0.5, 0.1, 0.05, 0.0],    # After \"on\", \"the\" is likely\n",
        "    [0.05, 0.05, 0.05, 0.1, 0.1, 0.6, 0.05, 0.0]   # After \"the\", \"mat\" is likely\n",
        "])\n",
        "\n",
        "# Greedy Decoding\n",
        "def greedy_decode(probabilities, vocabulary):\n",
        "    # Select the highest probability word at each step\n",
        "    indices = np.argmax(probabilities, axis=1)\n",
        "    decoded_sequence = vocabulary[indices]\n",
        "    return decoded_sequence.tolist()\n",
        "\n",
        "# Beam Search Decoding\n",
        "def beam_search_decode(probabilities, vocabulary, beam_width=2):\n",
        "    beams = [(np.array([], dtype=int), 1.0)]  # Each element is (sequence, probability)\n",
        "\n",
        "    for step_probs in probabilities:\n",
        "        new_beams = []\n",
        "        for seq, seq_prob in beams:\n",
        "            # Expand each beam sequence to all possible words\n",
        "            for i, word_prob in enumerate(step_probs):\n",
        "                new_seq = np.append(seq, i)\n",
        "                new_prob = seq_prob * word_prob\n",
        "                new_beams.append((new_seq, new_prob))\n",
        "\n",
        "        # Keep only top `beam_width` sequences based on probability\n",
        "        new_beams.sort(key=lambda x: x[1], reverse=True)\n",
        "        beams = new_beams[:beam_width]\n",
        "\n",
        "    # Take the highest probability sequence after all steps\n",
        "    best_sequence = beams[0][0]\n",
        "    return vocabulary[best_sequence].tolist()\n",
        "\n",
        "# Run Greedy Decoding\n",
        "greedy_result = greedy_decode(probabilities, vocabulary)\n",
        "print(\"Greedy Decoding Result:\", ' '.join(greedy_result))\n",
        "\n",
        "# Run Beam Search Decoding with beam width = 2\n",
        "beam_result = beam_search_decode(probabilities, vocabulary, beam_width=2)\n",
        "print(\"Beam Search Decoding Result:\", ' '.join(beam_result))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Vocabulary of words\n",
        "vocabulary = np.array([\"The\", \"cat\", \"sat\", \"on\", \"the\", \"mat\", \"in\", \"sun\"])\n",
        "\n",
        "# Dummy probability distributions for each step (rows are steps, columns correspond to vocabulary words)\n",
        "# These probabilities simulate a language model trying to form a meaningful sentence\n",
        "probabilities = np.array([\n",
        "    [0.2, 0.6, 0.05, 0.05, 0.05, 0.05, 0.0, 0.0],  # After \"The\", \"cat\" is likely\n",
        "    [0.1, 0.1, 0.6, 0.1, 0.05, 0.05, 0.0, 0.0],    # After \"cat\", \"sat\" is likely\n",
        "    [0.05, 0.1, 0.1, 0.5, 0.2, 0.05, 0.0, 0.0],    # After \"sat\", \"on\" is likely\n",
        "    [0.05, 0.1, 0.1, 0.1, 0.5, 0.1, 0.05, 0.0],    # After \"on\", \"the\" is likely\n",
        "    [0.05, 0.05, 0.05, 0.1, 0.1, 0.6, 0.05, 0.0]   # After \"the\", \"mat\" is likely\n",
        "])\n",
        "\n",
        "# Greedy Decoding\n",
        "def greedy_decode(probabilities, vocabulary):\n",
        "    # Select the highest probability word at each step\n",
        "    indices = np.argmax(probabilities, axis=1)\n",
        "    decoded_sequence = vocabulary[indices]\n",
        "    return decoded_sequence.tolist()\n",
        "\n",
        "# Beam Search Decoding\n",
        "def beam_search_decode(probabilities, vocabulary, beam_width=2):\n",
        "    # Initialize beams with empty sequences and probability 1\n",
        "    beams = [(np.array([], dtype=int), 1.0)]  # List of (sequence, probability)\n",
        "\n",
        "    for step_probs in probabilities:\n",
        "        new_beams = []\n",
        "        for seq, seq_prob in beams:\n",
        "            # For each beam, expand to all possible words\n",
        "            for i, word_prob in enumerate(step_probs):\n",
        "                new_seq = np.append(seq, i)\n",
        "                new_prob = seq_prob * word_prob\n",
        "                new_beams.append((new_seq, new_prob))\n",
        "\n",
        "        # Sort beams by probability, keeping the top `beam_width`\n",
        "        new_beams.sort(key=lambda x: x[1], reverse=True)\n",
        "        beams = new_beams[:beam_width]\n",
        "\n",
        "    # Take the highest probability sequence after all steps\n",
        "    best_sequence = beams[0][0]\n",
        "    return vocabulary[best_sequence].tolist()\n",
        "\n",
        "# Run Greedy Decoding\n",
        "greedy_result = greedy_decode(probabilities, vocabulary)\n",
        "print(\"Greedy Decoding Result:\", greedy_result)\n",
        "\n",
        "# Run Beam Search Decoding with beam width = 2\n",
        "beam_result = beam_search_decode(probabilities, vocabulary, beam_width=2)\n",
        "print(\"Beam Search Decoding Result:\", beam_result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "FkWa9IA1Iqpl",
        "outputId": "10a3b555-f0cf-43c5-a7ff-e4ae7a5f9756"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Greedy Decoding Result: ['cat', 'sat', 'on', 'the', 'mat']\n",
            "Beam Search Decoding Result: ['cat', 'sat', 'on', 'the', 'mat']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wwTGKVTcIqYP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}