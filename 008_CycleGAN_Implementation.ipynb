{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "id": "eaBL0rsILD9F",
        "outputId": "7bcf9427-4557-4143-919c-368e250ca453"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_8\" is incompatible with the layer: expected axis -1 of input shape to have value 6272, but received input with shape (64, 25088)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(64, 56, 56, 1), dtype=float32)\n  • training=None\n  • mask=None",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-f90f19467d8d>\u001b[0m in \u001b[0;36m<cell line: 137>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;31m# Train CycleGAN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m \u001b[0mtrain_cyclegan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-f90f19467d8d>\u001b[0m in \u001b[0;36mtrain_cyclegan\u001b[0;34m(G, F, D_X, D_Y, epochs, batch_size, lambda_cycle)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0mreal_X_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0mfake_X_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m                 \u001b[0mreal_Y_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD_Y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0mfake_Y_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD_Y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    225\u001b[0m                     \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 }:\n\u001b[0;32m--> 227\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m    228\u001b[0m                         \u001b[0;34mf'Input {input_index} of layer \"{layer_name}\" is '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                         \u001b[0;34mf\"incompatible with the layer: expected axis {axis} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_8\" is incompatible with the layer: expected axis -1 of input shape to have value 6272, but received input with shape (64, 25088)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(64, 56, 56, 1), dtype=float32)\n  • training=None\n  • mask=None"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load MNIST dataset (we'll use digits \"1\" and \"7\" as two domains)\n",
        "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Filter only digits \"1\" and \"7\"\n",
        "domain_X = train_images[train_labels == 1]  # Digit 1\n",
        "domain_Y = train_images[train_labels == 7]  # Digit 7\n",
        "\n",
        "# Normalize the images\n",
        "domain_X = (domain_X.astype('float32') - 127.5) / 127.5\n",
        "domain_X = domain_X.reshape(domain_X.shape[0], 28, 28, 1)\n",
        "\n",
        "domain_Y = (domain_Y.astype('float32') - 127.5) / 127.5\n",
        "domain_Y = domain_Y.reshape(domain_Y.shape[0], 28, 28, 1)\n",
        "\n",
        "# Generator Model (transform between domains)\n",
        "def build_generator():\n",
        "    model = tf.keras.Sequential([\n",
        "        layers.Conv2D(64, (3,3), padding='same', input_shape=(28, 28, 1)),\n",
        "        layers.LeakyReLU(),\n",
        "        layers.Conv2D(128, (3,3), padding='same'),\n",
        "        layers.LeakyReLU(),\n",
        "        layers.Conv2DTranspose(64, (3,3), strides=2, padding='same'),\n",
        "        layers.LeakyReLU(),\n",
        "        layers.Conv2DTranspose(1, (3,3), padding='same', activation='tanh')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Discriminator Model (distinguish between real and fake images)\n",
        "# Discriminator Model (distinguish between real and fake images)\n",
        "def build_discriminator():\n",
        "    model = tf.keras.Sequential([\n",
        "        layers.Conv2D(64, (3,3), strides=2, padding='same', input_shape=(28, 28, 1)),  # Added padding='same'\n",
        "        layers.LeakyReLU(),\n",
        "        layers.Conv2D(128, (3,3), strides=2, padding='same'),  # Added padding='same'\n",
        "        layers.LeakyReLU(),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(1)\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# CycleGAN Losses\n",
        "def cycle_loss(real_image, cycled_image, lambda_cycle=10):\n",
        "    return lambda_cycle * tf.reduce_mean(tf.abs(real_image - cycled_image))\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    return tf.keras.losses.BinaryCrossentropy()(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = tf.keras.losses.BinaryCrossentropy()(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = tf.keras.losses.BinaryCrossentropy()(tf.zeros_like(fake_output), fake_output)\n",
        "    return real_loss + fake_loss\n",
        "\n",
        "# Training Step for CycleGAN\n",
        "def train_cyclegan(G, F, D_X, D_Y, epochs=50, batch_size=64, lambda_cycle=10):\n",
        "    generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "    discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for i in range(min(domain_X.shape[0], domain_Y.shape[0]) // batch_size):\n",
        "            # Get mini-batch of data from both domains\n",
        "            real_X = domain_X[i*batch_size:(i+1)*batch_size]\n",
        "            real_Y = domain_Y[i*batch_size:(i+1)*batch_size]\n",
        "\n",
        "            # Generate fake images\n",
        "            fake_Y = G(real_X)\n",
        "            fake_X = F(real_Y)\n",
        "\n",
        "            # Cycled images\n",
        "            cycled_X = F(fake_Y)\n",
        "            cycled_Y = G(fake_X)\n",
        "\n",
        "            # Train discriminators\n",
        "            with tf.GradientTape() as tape:\n",
        "                real_X_output = D_X(real_X)\n",
        "                fake_X_output = D_X(fake_X)\n",
        "                real_Y_output = D_Y(real_Y)\n",
        "                fake_Y_output = D_Y(fake_Y)\n",
        "\n",
        "                d_X_loss = discriminator_loss(real_X_output, fake_X_output)\n",
        "                d_Y_loss = discriminator_loss(real_Y_output, fake_Y_output)\n",
        "\n",
        "            d_X_gradients = tape.gradient(d_X_loss, D_X.trainable_variables)\n",
        "            d_Y_gradients = tape.gradient(d_Y_loss, D_Y.trainable_variables)\n",
        "\n",
        "            discriminator_optimizer.apply_gradients(zip(d_X_gradients, D_X.trainable_variables))\n",
        "            discriminator_optimizer.apply_gradients(zip(d_Y_gradients, D_Y.trainable_variables))\n",
        "\n",
        "            # Train generators\n",
        "            with tf.GradientTape() as tape:\n",
        "                fake_Y = G(real_X)\n",
        "                fake_X = F(real_Y)\n",
        "\n",
        "                real_X_output = D_X(real_X)\n",
        "                real_Y_output = D_Y(real_Y)\n",
        "                fake_X_output = D_X(fake_X)\n",
        "                fake_Y_output = D_Y(fake_Y)\n",
        "\n",
        "                g_loss = generator_loss(fake_Y_output) + cycle_loss(real_X, cycled_X, lambda_cycle)\n",
        "                f_loss = generator_loss(fake_X_output) + cycle_loss(real_Y, cycled_Y, lambda_cycle)\n",
        "\n",
        "            g_gradients = tape.gradient(g_loss, G.trainable_variables)\n",
        "            f_gradients = tape.gradient(f_loss, F.trainable_variables)\n",
        "\n",
        "            generator_optimizer.apply_gradients(zip(g_gradients, G.trainable_variables))\n",
        "            generator_optimizer.apply_gradients(zip(f_gradients, F.trainable_variables))\n",
        "\n",
        "        print(f'Epoch: {epoch+1}, D_X Loss: {d_X_loss}, D_Y Loss: {d_Y_loss}, G Loss: {g_loss}, F Loss: {f_loss}')\n",
        "\n",
        "    # Generate transformed images\n",
        "    noise_X = domain_X[:16]\n",
        "    noise_Y = domain_Y[:16]\n",
        "\n",
        "    generated_Y = G(noise_X)\n",
        "    generated_X = F(noise_Y)\n",
        "\n",
        "    # Plot images\n",
        "    for i in range(16):\n",
        "        plt.subplot(4, 4, i+1)\n",
        "        if i < 8:\n",
        "            plt.imshow(generated_Y[i, :, :, 0] * 127.5 + 127.5, cmap=\"gray\")\n",
        "        else:\n",
        "            plt.imshow(generated_X[i-8, :, :, 0] * 127.5 + 127.5, cmap=\"gray\")\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Build models\n",
        "G = build_generator()  # X to Y\n",
        "F = build_generator()  # Y to X\n",
        "D_X = build_discriminator()  # Discriminator for domain X\n",
        "D_Y = build_discriminator()  # Discriminator for domain Y\n",
        "\n",
        "# Train CycleGAN\n",
        "train_cyclegan(G, F, D_X, D_Y)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cGAN_mnist.py\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load MNIST dataset\n",
        "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()\n",
        "train_images = (train_images.astype('float32') - 127.5) / 127.5\n",
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1)\n",
        "\n",
        "# Generator Model\n",
        "def build_generator():\n",
        "    model = tf.keras.Sequential([\n",
        "        layers.Dense(256, input_shape=(110,)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.LeakyReLU(),\n",
        "        layers.Dense(512),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.LeakyReLU(),\n",
        "        layers.Dense(1024),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.LeakyReLU(),\n",
        "        layers.Dense(28*28, activation=\"tanh\"),\n",
        "        layers.Reshape((28, 28, 1))\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Discriminator Model\n",
        "def build_discriminator():\n",
        "    model = tf.keras.Sequential([\n",
        "        layers.Flatten(input_shape=(28, 28, 11)),\n",
        "        layers.Dense(512),\n",
        "        layers.LeakyReLU(),\n",
        "        layers.Dense(256),\n",
        "        layers.LeakyReLU(),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Concatenate noise with label embeddings\n",
        "def concatenate_label_and_noise(labels, noise):\n",
        "    label_embeddings = tf.one_hot(labels, depth=10)\n",
        "    noise_with_labels = tf.concat([noise, label_embeddings], axis=1)\n",
        "    return noise_with_labels\n",
        "\n",
        "# Conditional GAN training step\n",
        "class cGAN(tf.keras.Model):\n",
        "    def __init__(self, generator, discriminator, noise_dim):\n",
        "        super(cGAN, self).__init__()\n",
        "        self.generator = generator\n",
        "        self.discriminator = discriminator\n",
        "        self.noise_dim = noise_dim\n",
        "\n",
        "    def compile(self, generator_optimizer, discriminator_optimizer):\n",
        "        super(cGAN, self).compile()\n",
        "        self.generator_optimizer = generator_optimizer\n",
        "        self.discriminator_optimizer = discriminator_optimizer\n",
        "\n",
        "    def train_step(self, data):\n",
        "        real_images, labels = data\n",
        "        batch_size = tf.shape(real_images)[0]\n",
        "        noise = tf.random.normal([batch_size, self.noise_dim])\n",
        "        noise_with_labels = concatenate_label_and_noise(labels, noise)\n",
        "\n",
        "        # Train Discriminator\n",
        "        with tf.GradientTape() as tape:\n",
        "            generated_images = self.generator(noise_with_labels)\n",
        "            real_input = tf.concat([real_images, tf.one_hot(labels, 10)], axis=-1)\n",
        "            fake_input = tf.concat([generated_images, tf.one_hot(labels, 10)], axis=-1)\n",
        "\n",
        "            real_output = self.discriminator(real_input)\n",
        "            fake_output = self.discriminator(fake_input)\n",
        "\n",
        "            d_loss = tf.keras.losses.BinaryCrossentropy()(tf.ones_like(real_output), real_output) + \\\n",
        "                     tf.keras.losses.BinaryCrossentropy()(tf.zeros_like(fake_output), fake_output)\n",
        "        gradients = tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
        "        self.discriminator_optimizer.apply_gradients(zip(gradients, self.discriminator.trainable_variables))\n",
        "\n",
        "        # Train Generator\n",
        "        noise_with_labels = concatenate_label_and_noise(labels, noise)\n",
        "        with tf.GradientTape() as tape:\n",
        "            generated_images = self.generator(noise_with_labels)\n",
        "            fake_input = tf.concat([generated_images, tf.one_hot(labels, 10)], axis=-1)\n",
        "            fake_output = self.discriminator(fake_input)\n",
        "            g_loss = tf.keras.losses.BinaryCrossentropy()(tf.ones_like(fake_output), fake_output)\n",
        "        gradients = tape.gradient(g_loss, self.generator.trainable_variables)\n",
        "        self.generator_optimizer.apply_gradients(zip(gradients, self.generator.trainable_variables))\n",
        "\n",
        "        return {\"d_loss\": d_loss, \"g_loss\": g_loss}\n",
        "\n",
        "# Instantiate and Train cGAN\n",
        "generator = build_generator()\n",
        "discriminator = build_discriminator()\n",
        "cgan = cGAN(generator, discriminator, noise_dim=100)\n",
        "\n",
        "cgan.compile(\n",
        "    generator_optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "    discriminator_optimizer=tf.keras.optimizers.Adam(1e-4)\n",
        ")\n",
        "\n",
        "cgan.fit((train_images, train_labels), epochs=50, batch_size=64)\n",
        "\n",
        "# Generate Conditional Images after Training\n",
        "noise = tf.random.normal([16, 100])\n",
        "labels = tf.constant([i for i in range(10)] * 2)\n",
        "noise_with_labels = concatenate_label_and_noise(labels, noise)\n",
        "generated_images = generator(noise_with_labels)\n",
        "\n",
        "for i in range(16):\n",
        "    plt.subplot(4, 4, i+1)\n",
        "    plt.imshow(generated_images[i, :, :, 0] * 127.5 + 127.5, cmap=\"gray\")\n",
        "    plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "Gm1uRMDOT2q9",
        "outputId": "3c050dca-412e-4cb6-b126-410c560d7f04"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "not enough values to unpack (expected 2, got 1)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-dd1188d55ba2>\u001b[0m in \u001b[0;36m<cell line: 101>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     99\u001b[0m )\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m \u001b[0mcgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m# Generate Conditional Images after Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-dd1188d55ba2>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mreal_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise_dim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
          ]
        }
      ]
    }
  ]
}