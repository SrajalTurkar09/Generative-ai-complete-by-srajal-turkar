{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "B-62xQNDepx7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist  # Example dataset for simplicity, replace with 3D dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c5amagfufQM9"
   },
   "source": [
    "```Explanation of the code:\n",
    "We import the necessary libraries for building, training, and visualizing our 3D GAN. TensorFlow is used to build the models, and matplotlib is used for visualization. We use the mnist dataset as a placeholder (replace with your own 3D data).```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5JOe1JMUeu9s"
   },
   "outputs": [],
   "source": [
    "def build_generator(latent_dim):\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    model.add(layers.Dense(4*4*4*512, activation=\"relu\", input_dim=latent_dim))\n",
    "    model.add(layers.Reshape((4, 4, 4, 512)))\n",
    "    model.add(layers.Conv3DTranspose(256, kernel_size=4, strides=2, padding=\"same\", activation=\"relu\"))\n",
    "    model.add(layers.Conv3DTranspose(128, kernel_size=4, strides=2, padding=\"same\", activation=\"relu\"))\n",
    "    model.add(layers.Conv3DTranspose(64, kernel_size=4, strides=2, padding=\"same\", activation=\"relu\"))\n",
    "    model.add(layers.Conv3DTranspose(1, kernel_size=4, strides=2, padding=\"same\", activation=\"sigmoid\"))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vn28LaGyfTrU"
   },
   "source": [
    "```The Generator model is defined here. It takes a latent vector as input and outputs a 3D voxel grid. The model uses Dense layers and 3D convolutional transpose layers to upsample the latent vector into a 3D voxel grid.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7Vzba8oDewP8"
   },
   "outputs": [],
   "source": [
    "# def build_discriminator(input_shape):\n",
    "#     model = tf.keras.Sequential()\n",
    "\n",
    "#     model.add(layers.Conv3D(64, kernel_size=4, strides=2, padding=\"same\", input_shape=input_shape))\n",
    "#     model.add(layers.LeakyReLU(alpha=0.2))\n",
    "#     model.add(lers.Conv3D(128, kernel_size=4, strides=2, padding=\"same\"))\n",
    "#     model.add(layers.LeakyReLU(alpha=0.2))\n",
    "#     model.add(layers.Conv3D(256, kernel_size=4, strides=2, padding=\"same\"))\n",
    "#     model.add(layers.LeakyReLU(alpha=0.2))\n",
    "#     model.add(layers.Conv3D(512, kernel_size=4, strides=2, padding=\"same\"))\n",
    "#     model.add(layers.LeakyReLU(alpha=0.2))\n",
    "#     model.add(layers.Flatten())\n",
    "#     model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "#     return model\n",
    "# #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3WWjwLPkfEoj"
   },
   "outputs": [],
   "source": [
    "def build_discriminator(input_shape):\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    model.add(layers.Conv3D(64, kernel_size=4, strides=2, padding=\"same\", input_shape=input_shape))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Conv3D(128, kernel_size=4, strides=2, padding=\"same\")) # Changed 'lers' to 'layers'\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Conv3D(256, kernel_size=4, strides=2, padding=\"same\"))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Conv3D(512, kernel_size=4, strides=2, padding=\"same\"))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tBvk-yyEfans"
   },
   "source": [
    "```The Discriminator model is defined here. It takes a 3D voxel grid as input and outputs a scalar value (0 for fake, 1 for real). The model uses 3D convolution layers followed by a Dense layer to produce a final output.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0fEQmN_6eyPq"
   },
   "outputs": [],
   "source": [
    "def build_gan(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gkZ1CASGfeNv"
   },
   "source": [
    "```The combined GAN model is defined here. The generator is connected to the discriminator to create a complete model. The discriminatorâ€™s weights are frozen during the generator's training to ensure that only the generator is updated.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PUQHGYjiezeu",
    "outputId": "81238275-5154-4173-ba07-1ede6cd9be44"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rishu\\AppData\\Local\\anaconda3\\envs\\rexxes\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\Rishu\\AppData\\Local\\anaconda3\\envs\\rexxes\\lib\\site-packages\\keras\\src\\layers\\activations\\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rishu\\AppData\\Local\\anaconda3\\envs\\rexxes\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Optimizers\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "\n",
    "# Loss Function\n",
    "binary_crossentropy = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "# Build and Compile the Discriminator\n",
    "discriminator = build_discriminator((64, 64, 64, 1))\n",
    "discriminator.compile(loss=binary_crossentropy, optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "# Build the Generator\n",
    "latent_dim = 100\n",
    "generator = build_generator(latent_dim)\n",
    "\n",
    "# Build the GAN (generator + discriminator)\n",
    "gan = build_gan(generator, discriminator)\n",
    "gan.compile(loss=binary_crossentropy, optimizer=optimizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uR9nVAB5ghB3"
   },
   "source": [
    "```We define the Adam optimizer for training and binary cross-entropy loss for both the generator and discriminator. The discriminator and GAN are compiled with these settings.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "eMGuEIxre197"
   },
   "outputs": [],
   "source": [
    "def train_gan(generator, discriminator, gan, epochs, batch_size, latent_dim, dataset):\n",
    "    half_batch = batch_size // 2\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Train Discriminator\n",
    "        idx = np.random.randint(0, dataset.shape[0], half_batch)\n",
    "        real_voxels = dataset[idx]\n",
    "        real_voxels = real_voxels.reshape((half_batch, 64, 64, 64, 1))\n",
    "\n",
    "        noise = np.random.normal(0, 1, (half_batch, latent_dim))\n",
    "        fake_voxels = generator.predict(noise)\n",
    "\n",
    "        # Labels for real and fake images\n",
    "        real_labels = np.ones((half_batch, 1))\n",
    "        fake_labels = np.zeros((half_batch, 1))\n",
    "\n",
    "        # Train on real and fake images\n",
    "        d_loss_real = discriminator.train_on_batch(real_voxels, real_labels)\n",
    "        d_loss_fake = discriminator.train_on_batch(fake_voxels, fake_labels)\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "        # Train Generator (through GAN model)\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        valid_labels = np.ones((batch_size, 1))\n",
    "\n",
    "        g_loss = gan.train_on_batch(noise, valid_labels)\n",
    "\n",
    "        # Print the progress\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"{epoch}/{epochs} [D loss: {d_loss[0]} | D accuracy: {100 * d_loss[1]}] [G loss: {g_loss}]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ELsVFW7gnwf"
   },
   "source": [
    "```The training loop involves alternating between training the discriminator and the generator. The discriminator is trained on real and fake images, while the generator is trained through the combined GAN model to create realistic voxel grids.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "hQPFRAgDe8Ap"
   },
   "outputs": [],
   "source": [
    "def plot_generated_voxel(voxels, epoch, examples=10, dim=(1, 10), figsize=(10, 1)):\n",
    "    # Plot a batch of generated voxels\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(examples):\n",
    "        ax = plt.subplot(dim[0], dim[1], i + 1)\n",
    "        ax.imshow(voxels[i, :, :, 32, 0], cmap='gray')  # View the middle slice of the voxel grid\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"generated_voxels_epoch_{epoch}.png\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zzBLBhotgrL_"
   },
   "source": [
    "```The visualization function generates and saves images of the middle slices of the 3D voxel grids produced by the generator. This helps visualize the generated 3D data.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "u-Owvpare9Qa"
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 11.2 GiB for an array with shape (60000, 1792, 28, 1) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m X_train \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n\u001b[0;32m      5\u001b[0m X_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(X_train, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Add channel dimension\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Dummy 3D data, expand to (64, 64, 64)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m X_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(X_train, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Add channel dimension for consistency\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Rishu\\AppData\\Local\\anaconda3\\envs\\rexxes\\lib\\site-packages\\numpy\\core\\fromnumeric.py:466\u001b[0m, in \u001b[0;36mrepeat\u001b[1;34m(a, repeats, axis)\u001b[0m\n\u001b[0;32m    423\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_repeat_dispatcher)\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrepeat\u001b[39m(a, repeats, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    425\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;124;03m    Repeat each element of an array after themselves\u001b[39;00m\n\u001b[0;32m    427\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    464\u001b[0m \n\u001b[0;32m    465\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 466\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrepeat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepeats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Rishu\\AppData\\Local\\anaconda3\\envs\\rexxes\\lib\\site-packages\\numpy\\core\\fromnumeric.py:59\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 11.2 GiB for an array with shape (60000, 1792, 28, 1) and data type float32"
     ]
    }
   ],
   "source": [
    "# For the sake of demonstration, we'll use a 2D dataset (MNIST)\n",
    "# Load dataset and preprocess it into 64x64x64 voxel grids\n",
    "(X_train, _), (_, _) = mnist.load_data()\n",
    "X_train = X_train.astype(np.float32) / 255.0\n",
    "X_train = np.expand_dims(X_train, axis=-1)  # Add channel dimension\n",
    "X_train = np.repeat(X_train, 64, axis=1)  # Dummy 3D data, expand to (64, 64, 64)\n",
    "X_train = np.expand_dims(X_train, axis=-1)  # Add channel dimension for consistency\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K0dPqQqQgt75"
   },
   "source": [
    "```This section loads and preprocesses the dataset. Here, we use the MNIST dataset as a placeholder, but for real use cases, you should replace this with actual 3D voxel datasets.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "gtIL9656e-2P"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 3010560000 into shape (64,64,64,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10000\u001b[39m\n\u001b[0;32m      3\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 3010560000 into shape (64,64,64,1)"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape((-1, 64, 64, 64, 1))\n",
    "epochs = 10000\n",
    "batch_size = 64\n",
    "\n",
    "train_gan(generator, discriminator, gan, epochs, batch_size, latent_dim, X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qEugHw9JgxF5"
   },
   "source": [
    "```This starts the training process, where the generator and discriminator are trained for the specified number of epochs and batch size.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yrv6gyVjfIuC"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
