{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# code from scratch"
      ],
      "metadata": {
        "id": "8NHZuyu9S882"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. NICE (Non-linear Independent Components Estimation)\n"
      ],
      "metadata": {
        "id": "N6ICEfN8TCDb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "2AtAx5YGSdgZ",
        "outputId": "310f2378-d060-4d55-c910-fef3ea858f50"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "Exception encountered when calling AdditiveCoupling.call().\n\n\u001b[1m{{function_node __wrapped__Split_num_split_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Number of ways to split should evenly divide the split dimension, but got split_dim 3 (size = 1) and num_split 2 [Op:Split] name: split\u001b[0m\n\nArguments received by AdditiveCoupling.call():\n  • x=tf.Tensor(shape=(32, 28, 28, 1), dtype=float32)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a771fe5d41c5>\u001b[0m in \u001b[0;36m<cell line: 44>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# Forward pass (data transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Batch of 32 samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnice_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m# Inverse pass (sampling)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-a771fe5d41c5>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-a771fe5d41c5>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_or_size_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0my2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Simple additive function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Exception encountered when calling AdditiveCoupling.call().\n\n\u001b[1m{{function_node __wrapped__Split_num_split_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Number of ways to split should evenly divide the split dimension, but got split_dim 3 (size = 1) and num_split 2 [Op:Split] name: split\u001b[0m\n\nArguments received by AdditiveCoupling.call():\n  • x=tf.Tensor(shape=(32, 28, 28, 1), dtype=float32)"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Define the coupling layer for NICE\n",
        "class AdditiveCoupling(layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(AdditiveCoupling, self).__init__()\n",
        "\n",
        "    def call(self, x):\n",
        "        x1, x2 = tf.split(x, num_or_size_splits=2, axis=-1)\n",
        "        y1 = x1\n",
        "        y2 = x2 + tf.nn.tanh(x1)  # Simple additive function\n",
        "        return tf.concat([y1, y2], axis=-1)\n",
        "\n",
        "    def inverse(self, y):\n",
        "        y1, y2 = tf.split(y, num_or_size_splits=2, axis=-1)\n",
        "        x1 = y1\n",
        "        x2 = y2 - tf.nn.tanh(y1)\n",
        "        return tf.concat([x1, x2], axis=-1)\n",
        "\n",
        "# Define the NICE model with multiple coupling layers\n",
        "class NICEModule(keras.Model):\n",
        "    def __init__(self):\n",
        "        super(NICEModule, self).__init__()\n",
        "        self.layers_ = [AdditiveCoupling() for _ in range(4)]  # Stack 4 layers\n",
        "\n",
        "    def call(self, x):\n",
        "        for layer in self.layers_:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "    def inverse(self, y):\n",
        "        for layer in reversed(self.layers_):\n",
        "            y = layer.inverse(y)\n",
        "        return y\n",
        "\n",
        "# Create the NICE model\n",
        "input_shape = (28, 28, 1)  # Example input shape (e.g., MNIST)\n",
        "nice_model = NICEModule()\n",
        "\n",
        "# Forward pass (data transformation)\n",
        "x = tf.random.normal((32, 28, 28, 1))  # Batch of 32 samples\n",
        "y = nice_model(x)\n",
        "\n",
        "# Inverse pass (sampling)\n",
        "x_reconstructed = nice_model.inverse(y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. RealNVP (Real-valued Non-Volume Preserving)\n"
      ],
      "metadata": {
        "id": "RkA5gddLTFqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_probability as tfp\n",
        "tfd = tfp.distributions\n",
        "tfpl = tfp.layers\n",
        "\n",
        "# Define the affine coupling layer for RealNVP\n",
        "class AffineCoupling(layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(AffineCoupling, self).__init__()\n",
        "\n",
        "    def call(self, x):\n",
        "        x1, x2 = tf.split(x, num_or_size_splits=2, axis=-1)\n",
        "        shift = tf.nn.tanh(x1)\n",
        "        log_scale = tf.nn.tanh(x1)\n",
        "        y1 = x1\n",
        "        y2 = x2 * tf.exp(log_scale) + shift\n",
        "        return tf.concat([y1, y2], axis=-1)\n",
        "\n",
        "    def inverse(self, y):\n",
        "        y1, y2 = tf.split(y, num_or_size_splits=2, axis=-1)\n",
        "        shift = tf.nn.tanh(y1)\n",
        "        log_scale = tf.nn.tanh(y1)\n",
        "        x1 = y1\n",
        "        x2 = (y2 - shift) / tf.exp(log_scale)\n",
        "        return tf.concat([x1, x2], axis=-1)\n",
        "\n",
        "# Define the RealNVP model with multiple affine coupling layers\n",
        "class RealNVPModule(keras.Model):\n",
        "    def __init__(self):\n",
        "        super(RealNVPModule, self).__init__()\n",
        "        self.layers_ = [AffineCoupling() for _ in range(4)]  # Stack 4 layers\n",
        "\n",
        "    def call(self, x):\n",
        "        for layer in self.layers_:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "    def inverse(self, y):\n",
        "        for layer in reversed(self.layers_):\n",
        "            y = layer.inverse(y)\n",
        "        return y\n",
        "\n",
        "# Create the RealNVP model\n",
        "realnvp_model = RealNVPModule()\n",
        "\n",
        "# Forward pass (data transformation)\n",
        "x = tf.random.normal((32, 28, 28, 1))  # Batch of 32 samples\n",
        "y = realnvp_model(x)\n",
        "\n",
        "# Inverse pass (sampling)\n",
        "x_reconstructed = realnvp_model.inverse(y)\n"
      ],
      "metadata": {
        "id": "y87jXodBTGWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Glow (Invertible 1x1 Convolutions)\n"
      ],
      "metadata": {
        "id": "ZBQsrwTcTInz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the 1x1 invertible convolution layer for Glow\n",
        "class Invertible1x1Conv(layers.Layer):\n",
        "    def __init__(self, num_channels):\n",
        "        super(Invertible1x1Conv, self).__init__()\n",
        "        w_init = tf.random.normal([num_channels, num_channels])\n",
        "        self.w = tf.Variable(w_init, trainable=True)\n",
        "\n",
        "    def call(self, x):\n",
        "        shape = tf.shape(x)\n",
        "        x = tf.reshape(x, [-1, shape[-1]])\n",
        "        y = tf.matmul(x, self.w)\n",
        "        return tf.reshape(y, shape)\n",
        "\n",
        "    def inverse(self, y):\n",
        "        shape = tf.shape(y)\n",
        "        y = tf.reshape(y, [-1, shape[-1]])\n",
        "        w_inv = tf.linalg.inv(self.w)\n",
        "        x = tf.matmul(y, w_inv)\n",
        "        return tf.reshape(x, shape)\n",
        "\n",
        "# Define the Glow model with invertible 1x1 convolutions\n",
        "class GlowModule(keras.Model):\n",
        "    def __init__(self, num_channels):\n",
        "        super(GlowModule, self).__init__()\n",
        "        self.layers_ = [Invertible1x1Conv(num_channels) for _ in range(4)]  # Stack 4 layers\n",
        "\n",
        "    def call(self, x):\n",
        "        for layer in self.layers_:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "    def inverse(self, y):\n",
        "        for layer in reversed(self.layers_):\n",
        "            y = layer.inverse(y)\n",
        "        return y\n",
        "\n",
        "# Create the Glow model\n",
        "glow_model = GlowModule(num_channels=28*28)  # Example for image size\n",
        "\n",
        "# Forward pass (data transformation)\n",
        "x = tf.random.normal((32, 28, 28, 1))  # Batch of 32 samples\n",
        "y = glow_model(x)\n",
        "\n",
        "# Inverse pass (sampling)\n",
        "x_reconstructed = glow_model.inverse(y)\n"
      ],
      "metadata": {
        "id": "Kig5cgdaTJPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. RealNVP (Using TensorFlow Probability)\n"
      ],
      "metadata": {
        "id": "qqv1ycgdTSzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-probability\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "tfd = tfp.distributions\n",
        "tfb = tfp.bijectors\n",
        "\n",
        "def create_realnvp_model(input_shape):\n",
        "    # Define base distribution (e.g., standard normal)\n",
        "    base_dist = tfd.MultivariateNormalDiag(loc=tf.zeros(input_shape))\n",
        "\n",
        "    # Define bijectors (RealNVP layers)\n",
        "    bijectors = []\n",
        "    for i in range(2):  # Example with 2 RealNVP layers\n",
        "        bijectors.append(tfb.RealNVP(\n",
        "            num_masked=input_shape // 2,\n",
        "            shift_and_log_scale_fn=tfb.real_nvp_default_template(\n",
        "                hidden_layers=[512, 512]\n",
        "            )\n",
        "        ))\n",
        "        bijectors.append(tfb.Permute(permutation=[i for i in range(input_shape)])) # Permutation after each RealNVP\n",
        "\n",
        "    # Chain bijectors\n",
        "    bijector = tfb.Chain(bijectors)\n",
        "\n",
        "    # Create transformed distribution\n",
        "    return tfd.TransformedDistribution(\n",
        "        distribution=base_dist,\n",
        "        bijector=bijector\n",
        "    )\n",
        "\n",
        "\n",
        "    return realnvp_model\n",
        "\n",
        "# Apply the RealNVP model\n",
        "input_shape = 28 * 28  # Example for MNIST images (flattened)\n",
        "realnvp_model = create_realnvp_model(input_shape)\n",
        "\n",
        "# Example usage: Generate data\n",
        "samples = realnvp_model.sample(10)  # Generate 10 samples\n",
        "log_prob = realnvp_model.log_prob(samples)  # Calculate log likelihood\n",
        "print(\"Generated Samples: \", samples)\n",
        "print(\"Log Probability: \", log_prob)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnIxSTf1ToQT",
        "outputId": "90d49b4c-a68c-4641-a76f-07307a55fe60"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.10/dist-packages (0.24.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability) (1.4.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability) (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability) (1.26.4)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability) (2.2.1)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability) (0.6.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability) (0.1.8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/bijectors/real_nvp.py:393: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  x = tf_keras.tf1_layers.dense(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/bijectors/real_nvp.py:399: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  x = tf_keras.tf1_layers.dense(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Samples:  tf.Tensor(\n",
            "[[-0.82689685 -0.35740632 -0.28841424 ...  0.2582227  -1.4775872\n",
            "   1.4802727 ]\n",
            " [-0.2492197  -0.90530276 -0.47811446 ...  0.97475153 -0.20223337\n",
            "   1.3833971 ]\n",
            " [-0.23200765  0.33753997 -0.6723876  ...  0.6379681   0.24341452\n",
            "   2.7222257 ]\n",
            " ...\n",
            " [ 1.3190647  -0.12942575 -1.1176198  ...  0.73666245  0.1583738\n",
            "   0.9330384 ]\n",
            " [ 0.5885623  -0.60022354 -0.44780692 ... -0.22298717 -0.20464176\n",
            "  -0.18658447]\n",
            " [-0.31655037  0.99625     1.8196329  ... -0.06047153 -0.31841826\n",
            "   2.2305033 ]], shape=(10, 784), dtype=float32)\n",
            "Log Probability:  tf.Tensor(\n",
            "[-1115.6232 -1115.0029 -1123.6189 -1115.2931 -1154.9408 -1109.9989\n",
            " -1106.2806 -1146.9216 -1112.8838 -1104.9581], shape=(10,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  2. Glow (Using TensorFlow Probability)\n"
      ],
      "metadata": {
        "id": "YM0hG6mkTXsT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class InvertibleConv(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_channels):\n",
        "        super(InvertibleConv, self).__init__()\n",
        "        w_init = tf.random.normal([num_channels, num_channels])\n",
        "        self.w = tf.Variable(w_init, trainable=True)\n",
        "\n",
        "    def call(self, x):\n",
        "        shape = tf.shape(x)\n",
        "        x = tf.reshape(x, [-1, shape[-1]])\n",
        "        y = tf.matmul(x, self.w)\n",
        "        return tf.reshape(y, shape)\n",
        "\n",
        "    def inverse(self, y):\n",
        "        shape = tf.shape(y)\n",
        "        y = tf.reshape(y, [-1, shape[-1]])\n",
        "        w_inv = tf.linalg.inv(self.w)\n",
        "        x = tf.matmul(y, w_inv)\n",
        "        return tf.reshape(x, shape)\n",
        "\n",
        "# Glow Model using Invertible Conv\n",
        "class Glow(tf.keras.Model):\n",
        "    def __init__(self, num_channels):\n",
        "        super(Glow, self).__init__()\n",
        "        self.invertible_conv = InvertibleConv(num_channels)\n",
        "\n",
        "    def call(self, x):\n",
        "        return self.invertible_conv(x)\n",
        "\n",
        "    def inverse(self, y):\n",
        "        return self.invertible_conv.inverse(y)\n",
        "\n",
        "# Use Glow model\n",
        "glow_model = Glow(num_channels=28*28)  # Example for MNIST\n",
        "x = tf.random.normal((32, 28*28))  # Batch of 32 samples\n",
        "y = glow_model(x)\n",
        "x_reconstructed = glow_model.inverse(y)\n"
      ],
      "metadata": {
        "id": "uGkafIuvTVkU"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Steps to Apply on Real Problems:\n"
      ],
      "metadata": {
        "id": "X_znemsqTjFL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Image Generation (MNIST Example):\n"
      ],
      "metadata": {
        "id": "Mr0sLiOOTkur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use real-world dataset (MNIST in this case)\n",
        "(train_images, _), (_, _) = tf.keras.datasets.mnist.load_data()\n",
        "train_images = train_images.reshape(-1, 28*28).astype('float32') / 255.0\n",
        "\n",
        "# Define RealNVP model\n",
        "realnvp_model = create_realnvp_model(input_shape=28*28)\n",
        "\n",
        "# **Access trainable variables directly, not through 'layers'**\n",
        "for variable in realnvp_model.trainable_variables:\n",
        "    variable.trainable = True  # This line might be redundant, but ensures trainability\n",
        "\n",
        "# Train the model\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "\n",
        "# Training loop (simple example)\n",
        "for epoch in range(10):\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Random batch from dataset\n",
        "        batch = tf.random.shuffle(train_images)[:32]\n",
        "        neg_log_likelihood = -realnvp_model.log_prob(batch)  # Compute negative log-likelihood\n",
        "        loss = tf.reduce_mean(neg_log_likelihood)\n",
        "\n",
        "    gradients = tape.gradient(loss, realnvp_model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, realnvp_model.trainable_variables))\n",
        "    print(f'Epoch {epoch+1}, Loss: {loss.numpy()}')\n",
        "\n",
        "# Generate new samples\n",
        "generated_samples = realnvp_model.sample(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "_dqit-4xUeHD",
        "outputId": "d2da7f12-8daf-4abe-d650-3443e8b8f5fe"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "not enough values to unpack (expected 2, got 0)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-b90d99d05b85>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealnvp_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealnvp_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch {epoch+1}, Loss: {loss.numpy()}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0;31m# Return iterations for compat with tf.keras.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Anomaly Detection:\n"
      ],
      "metadata": {
        "id": "cCuZ1w2LTgk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume `test_data` is new data where we want to detect anomalies\n",
        "test_data = tf.random.normal((32, 28*28))\n",
        "\n",
        "# Calculate log-probability for each point\n",
        "log_probs = realnvp_model.log_prob(test_data)\n",
        "\n",
        "# Anomalies: Points with log-prob below a threshold\n",
        "threshold = -10.0  # Define a threshold for low probability\n",
        "anomalies = log_probs < threshold\n",
        "print(\"Anomalies Detected: \", anomalies)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLvSLk6pTfCu",
        "outputId": "7a27e32a-c20b-45d9-cc28-893d7dd91955"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Anomalies Detected:  tf.Tensor(\n",
            "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True], shape=(32,), dtype=bool)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yq9OthkJVUnn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}