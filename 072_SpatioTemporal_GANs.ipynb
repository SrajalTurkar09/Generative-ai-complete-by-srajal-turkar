{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9e02567",
   "metadata": {},
   "source": [
    "# Spatio-Temporal GANs for Video Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1055d9",
   "metadata": {},
   "source": [
    "This notebook implements a Spatio-Temporal GAN using TensorFlow and Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7490824",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Install TensorFlow if not already installed\n",
    "!pip install tensorflow\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6cc97e",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bb17e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load preprocessed video data\n",
    "# Shape: (num_videos, num_frames, height, width, channels)\n",
    "video_data = np.load('video_data.npy')  # Replace with your dataset path\n",
    "\n",
    "# Normalize pixel values to [-1, 1] for GANs\n",
    "video_data = (video_data.astype('float32') - 127.5) / 127.5\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fc25c4",
   "metadata": {},
   "source": [
    "## Generator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c546714b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.layers import Input, ConvLSTM2D, Conv3D, BatchNormalization, Activation, UpSampling3D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def build_generator(noise_dim, num_frames, height, width, channels):\n",
    "    input_noise = Input(shape=(noise_dim,))\n",
    "    \n",
    "    # Expand noise to a shape suitable for 3D convolution\n",
    "    x = tf.keras.layers.Dense(8 * 8 * 8 * 128, activation='relu')(input_noise)\n",
    "    x = tf.keras.layers.Reshape((8, 8, 8, 128))(x)  # Initial spatial dimensions (adjustable)\n",
    "\n",
    "    # Temporal dimension is added progressively\n",
    "    x = UpSampling3D(size=(2, 2, 2))(x)  # Expand spatially and temporally\n",
    "    x = Conv3D(128, kernel_size=3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # Add ConvLSTM for spatio-temporal modeling\n",
    "    x = ConvLSTM2D(64, kernel_size=3, padding='same', return_sequences=True)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # Output layer\n",
    "    x = Conv3D(channels, kernel_size=3, padding='same', activation='tanh')(x)\n",
    "\n",
    "    model = Model(input_noise, x)\n",
    "    return model\n",
    "\n",
    "# Hyperparameters\n",
    "noise_dim = 100\n",
    "num_frames = 16\n",
    "height, width, channels = 64, 64, 3\n",
    "\n",
    "generator = build_generator(noise_dim, num_frames, height, width, channels)\n",
    "generator.summary()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90f3c97",
   "metadata": {},
   "source": [
    "## Discriminator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1db05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.layers import Flatten, Dense, LeakyReLU\n",
    "\n",
    "def build_discriminator(num_frames, height, width, channels):\n",
    "    input_video = Input(shape=(num_frames, height, width, channels))\n",
    "    \n",
    "    # 3D Convolutional layers\n",
    "    x = Conv3D(64, kernel_size=3, strides=2, padding='same')(input_video)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = Conv3D(128, kernel_size=3, strides=2, padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = Conv3D(256, kernel_size=3, strides=2, padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # Classification output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(input_video, x)\n",
    "    return model\n",
    "\n",
    "discriminator = build_discriminator(num_frames, height, width, channels)\n",
    "discriminator.summary()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70529bd",
   "metadata": {},
   "source": [
    "## Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e762c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    return real_loss + fake_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32e7767",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde368fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow.keras.optimizers as optimizers\n",
    "\n",
    "# Optimizers\n",
    "generator_optimizer = optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "discriminator_optimizer = optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "\n",
    "# Training function\n",
    "@tf.function\n",
    "def train_step(videos):\n",
    "    noise = tf.random.normal([videos.shape[0], noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_videos = generator(noise, training=True)\n",
    "        \n",
    "        real_output = discriminator(videos, training=True)\n",
    "        fake_output = discriminator(generated_videos, training=True)\n",
    "        \n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "    \n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "    \n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "    \n",
    "    return gen_loss, disc_loss\n",
    "\n",
    "# Training loop\n",
    "def train(dataset, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        for batch in dataset:\n",
    "            gen_loss, disc_loss = train_step(batch)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}, Generator Loss: {gen_loss}, Discriminator Loss: {disc_loss}')\n",
    "\n",
    "# Prepare dataset\n",
    "batch_size = 16\n",
    "dataset = tf.data.Dataset.from_tensor_slices(video_data).shuffle(1000).batch(batch_size)\n",
    "\n",
    "# Train\n",
    "train(dataset, epochs=50)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b1872d",
   "metadata": {},
   "source": [
    "## Generate and Save Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09004c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_and_save_videos(generator, num_videos, noise_dim):\n",
    "    noise = tf.random.normal([num_videos, noise_dim])\n",
    "    generated_videos = generator(noise, training=False)\n",
    "    generated_videos = (generated_videos + 1) / 2  # Rescale to [0, 1]\n",
    "    \n",
    "    for i, video in enumerate(generated_videos):\n",
    "        plt.figure(figsize=(10, 2))\n",
    "        for t, frame in enumerate(video):\n",
    "            plt.subplot(1, video.shape[0], t + 1)\n",
    "            plt.imshow(frame)\n",
    "            plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "generate_and_save_videos(generator, num_videos=3, noise_dim=noise_dim)\n",
    "    "
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
