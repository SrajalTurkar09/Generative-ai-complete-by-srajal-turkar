{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOpTZeAOXc1t",
        "outputId": "2aae6232-e9a5-4f6b-8d9a-d48e54214a4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Reconstruction error: 0.3888888888888889\n",
            "Epoch 100: Reconstruction error: 0.3611111111111111\n",
            "Epoch 200: Reconstruction error: 0.3055555555555556\n",
            "Epoch 300: Reconstruction error: 0.3888888888888889\n",
            "Epoch 400: Reconstruction error: 0.16666666666666666\n",
            "Epoch 500: Reconstruction error: 0.3055555555555556\n",
            "Epoch 600: Reconstruction error: 0.25\n",
            "Epoch 700: Reconstruction error: 0.2777777777777778\n",
            "Epoch 800: Reconstruction error: 0.16666666666666666\n",
            "Epoch 900: Reconstruction error: 0.2222222222222222\n",
            "Hidden representation for test input: [[1 0]]\n",
            "Reconstruction from hidden representation: [[0 0 1 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "class RBM:\n",
        "    def __init__(self, n_visible, n_hidden, learning_rate=0.1):\n",
        "        \"\"\"\n",
        "        Initialize the RBM model.\n",
        "        n_visible: Number of visible units (input nodes)\n",
        "        n_hidden: Number of hidden units\n",
        "        learning_rate: The learning rate for weight updates\n",
        "        \"\"\"\n",
        "        self.n_visible = n_visible\n",
        "        self.n_hidden = n_hidden\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "        # Initialize weights and biases\n",
        "        self.weights = np.random.randn(n_visible, n_hidden) * 0.01\n",
        "        self.visible_bias = np.zeros(n_visible)\n",
        "        self.hidden_bias = np.zeros(n_hidden)\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        \"\"\"\n",
        "        Sigmoid activation function\n",
        "        \"\"\"\n",
        "        return 1.0 / (1 + np.exp(-x))\n",
        "\n",
        "    def sample_hidden(self, visible):\n",
        "        \"\"\"\n",
        "        Sample hidden units given the visible layer.\n",
        "        \"\"\"\n",
        "        activation = np.dot(visible, self.weights) + self.hidden_bias\n",
        "        probabilities = self.sigmoid(activation)\n",
        "        return probabilities, np.random.binomial(1, probabilities)\n",
        "\n",
        "    def sample_visible(self, hidden):\n",
        "        \"\"\"\n",
        "        Sample visible units given the hidden layer.\n",
        "        \"\"\"\n",
        "        activation = np.dot(hidden, self.weights.T) + self.visible_bias\n",
        "        probabilities = self.sigmoid(activation)\n",
        "        return probabilities, np.random.binomial(1, probabilities)\n",
        "\n",
        "    def train(self, data, epochs=1000):\n",
        "        \"\"\"\n",
        "        Train the RBM using Contrastive Divergence (CD-1).\n",
        "        data: Training data (binary values, i.e., 0s and 1s)\n",
        "        epochs: Number of training iterations\n",
        "        \"\"\"\n",
        "        for epoch in range(epochs):\n",
        "            # Positive phase: Calculate probabilities and sample hidden units\n",
        "            positive_hidden_probs, positive_hidden_sample = self.sample_hidden(data)\n",
        "            positive_associations = np.dot(data.T, positive_hidden_sample)\n",
        "\n",
        "            # Negative phase: Reconstruct visible units from hidden samples\n",
        "            negative_visible_probs, negative_visible_sample = self.sample_visible(positive_hidden_sample)\n",
        "            negative_hidden_probs, _ = self.sample_hidden(negative_visible_sample)\n",
        "            negative_associations = np.dot(negative_visible_sample.T, negative_hidden_probs)\n",
        "\n",
        "            # Update weights and biases\n",
        "            self.weights += self.learning_rate * (positive_associations - negative_associations) / data.shape[0]\n",
        "            self.visible_bias += self.learning_rate * np.mean(data - negative_visible_sample, axis=0)\n",
        "            self.hidden_bias += self.learning_rate * np.mean(positive_hidden_probs - negative_hidden_probs, axis=0)\n",
        "\n",
        "            if epoch % 100 == 0:\n",
        "                error = np.mean(np.abs(data - negative_visible_sample))\n",
        "                print(f'Epoch {epoch}: Reconstruction error: {error}')\n",
        "\n",
        "    def run_visible(self, visible):\n",
        "        \"\"\"\n",
        "        Run visible units through the network to get hidden activations.\n",
        "        \"\"\"\n",
        "        hidden_probs, hidden_sample = self.sample_hidden(visible)\n",
        "        return hidden_sample\n",
        "\n",
        "    def run_hidden(self, hidden):\n",
        "        \"\"\"\n",
        "        Run hidden units through the network to get visible activations (reconstruction).\n",
        "        \"\"\"\n",
        "        visible_probs, visible_sample = self.sample_visible(hidden)\n",
        "        return visible_sample\n",
        "\n",
        "# Example Usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Define training data (e.g., binary data with 6 visible units)\n",
        "    training_data = np.array([\n",
        "        [1, 1, 1, 0, 0, 0],\n",
        "        [1, 0, 1, 0, 0, 0],\n",
        "        [1, 1, 1, 0, 0, 0],\n",
        "        [0, 0, 1, 1, 1, 0],\n",
        "        [0, 0, 1, 1, 0, 0],\n",
        "        [0, 0, 1, 1, 1, 0]\n",
        "    ])\n",
        "\n",
        "    # Initialize RBM: 6 visible units, 2 hidden units\n",
        "    rbm = RBM(n_visible=6, n_hidden=2)\n",
        "\n",
        "    # Train RBM\n",
        "    rbm.train(training_data, epochs=1000)\n",
        "\n",
        "    # Example: Run input through the RBM and get hidden activations\n",
        "    test_input = np.array([[1, 0, 1, 0, 0, 0]])  # Example test input\n",
        "    hidden_representation = rbm.run_visible(test_input)\n",
        "    print(f'Hidden representation for test input: {hidden_representation}')\n",
        "\n",
        "    # Reconstruct the input from hidden units\n",
        "    reconstruction = rbm.run_hidden(hidden_representation)\n",
        "    print(f'Reconstruction from hidden representation: {reconstruction}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code Explanation\n",
        "Initialization (__init__):\n",
        "\n",
        "The RBM is initialized with the number of visible and hidden units.\n",
        "Weights and biases are initialized. Weights are small random numbers, while biases start at zero.\n",
        "Activation Function (sigmoid):\n",
        "\n",
        "Sigmoid is used to compute the probability that a hidden (or visible) unit is activated, given its inputs.\n",
        "Sampling Functions (sample_hidden, sample_visible):\n",
        "\n",
        "These functions compute the activation probabilities of the hidden/visible units and then sample the activations using binomial sampling.\n",
        "Training (train):\n",
        "\n",
        "The RBM is trained using Contrastive Divergence (CD-1).\n",
        "The algorithm performs a positive phase (sampling hidden units from data) and a negative phase (reconstructing visible units and resampling hidden units).\n",
        "Weights and biases are updated using the difference between positive and negative associations.\n",
        "Run Functions (run_visible, run_hidden):\n",
        "\n",
        "These functions allow you to get the hidden representation from a visible input or reconstruct a visible input from hidden units.\n",
        "Training Example:\n",
        "\n",
        "A simple binary dataset is used to train the RBM. After training, the RBM can infer hidden representations and reconstruct visible data."
      ],
      "metadata": {
        "id": "TopJGBmRXkND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.neural_network import BernoulliRBM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Define the training data (binary values)\n",
        "training_data = np.array([\n",
        "    [1, 1, 1, 0, 0, 0],\n",
        "    [1, 0, 1, 0, 0, 0],\n",
        "    [1, 1, 1, 0, 0, 0],\n",
        "    [0, 0, 1, 1, 1, 0],\n",
        "    [0, 0, 1, 1, 0, 0],\n",
        "    [0, 0, 1, 1, 1, 0]\n",
        "])\n",
        "\n",
        "# Normalize the data between 0 and 1 using MinMaxScaler\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "training_data_scaled = scaler.fit_transform(training_data)\n",
        "\n",
        "# Initialize the RBM\n",
        "rbm = BernoulliRBM(n_components=2, learning_rate=0.1, n_iter=1000, random_state=42)\n",
        "\n",
        "# Train the RBM\n",
        "rbm.fit(training_data_scaled)\n",
        "\n",
        "# Test example\n",
        "test_input = np.array([[1, 0, 1, 0, 0, 0]])\n",
        "test_input_scaled = scaler.transform(test_input)\n",
        "\n",
        "# Transform visible input to hidden layer representation\n",
        "hidden_representation = rbm.transform(test_input_scaled)\n",
        "print(f'Hidden representation for test input: {hidden_representation}')\n",
        "\n",
        "# Manually reconstruct visible layer from hidden layer\n",
        "# reconstruction = sigmoid(np.dot(hidden_representation, rbm.components_) + rbm.intercept_visible_)\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# Manually perform the reconstruction\n",
        "reconstruction_probabilities = sigmoid(np.dot(hidden_representation, rbm.components_) + rbm.intercept_visible_)\n",
        "print(f'Reconstructed visible layer (probabilities): {reconstruction_probabilities}')\n",
        "\n",
        "# Threshold the probabilities to get binary output (0 or 1)\n",
        "reconstructed_input = (reconstruction_probabilities > 0.5).astype(int)\n",
        "print(f'Reconstructed visible layer (binary): {reconstructed_input}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TwSMa1aXmao",
        "outputId": "0dd79983-5209-4aef-a8c4-965e4f53a27c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hidden representation for test input: [[0.01325487 0.01402122]]\n",
            "Reconstructed visible layer (probabilities): [[0.29488918 0.19650378 0.00604107 0.29532034 0.18897966 0.0067882 ]]\n",
            "Reconstructed visible layer (binary): [[0 0 0 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WmTmBCphYH46"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}