{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5f558f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Dense, Flatten, Reshape, Layer\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "(x_train, _), (x_test, _) = cifar10.load_data()\n",
    "\n",
    "# Normalize the data to the range [0, 1]\n",
    "x_train = x_train.astype(np.float32) / 255.0\n",
    "x_test = x_test.astype(np.float32) / 255.0\n",
    "\n",
    "# Reshape data for consistency\n",
    "x_train = x_train.reshape(-1, 32, 32, 3)\n",
    "x_test = x_test.reshape(-1, 32, 32, 3)\n",
    "\n",
    "class VectorQuantizer(Layer):\n",
    "    def __init__(self, num_embeddings, embedding_dim, commitment_cost=0.25):\n",
    "        super(VectorQuantizer, self).__init__()\n",
    "        self.num_embeddings = num_embeddings\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.commitment_cost = commitment_cost\n",
    "        self.embedding = self.add_weight(\n",
    "            name='embedding', shape=(self.num_embeddings, self.embedding_dim), initializer='uniform', trainable=True\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Calculate distances between input vectors and embedding vectors\n",
    "        flattened_inputs = tf.reshape(inputs, [-1, self.embedding_dim])\n",
    "        distances = tf.reduce_sum(flattened_inputs**2, axis=1, keepdims=True) - 2 * tf.matmul(flattened_inputs, self.embedding, transpose_b=True)\n",
    "        encoding_indices = tf.argmin(distances, axis=1)\n",
    "        encoding_indices = tf.reshape(encoding_indices, tf.shape(inputs)[:-1])\n",
    "\n",
    "        # Quantize\n",
    "        quantized = tf.gather(self.embedding, encoding_indices)\n",
    "\n",
    "        # Commitment loss\n",
    "        commitment_loss = self.commitment_cost * tf.reduce_mean((quantized - inputs) ** 2)\n",
    "\n",
    "        # Quantization error\n",
    "        quantized = inputs + tf.stop_gradient(quantized - inputs)\n",
    "\n",
    "        return quantized, commitment_loss\n",
    "\n",
    "class Encoder(Model):\n",
    "    def __init__(self, latent_dim=64):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = Conv2D(32, (4, 4), strides=2, padding=\"same\", activation=\"relu\")\n",
    "        self.conv2 = Conv2D(64, (4, 4), strides=2, padding=\"same\", activation=\"relu\")\n",
    "        self.conv3 = Conv2D(128, (4, 4), strides=2, padding=\"same\", activation=\"relu\")\n",
    "        self.flatten = Flatten()\n",
    "        self.dense = Dense(latent_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense(x)\n",
    "        return x\n",
    "\n",
    "class Decoder(Model):\n",
    "    def __init__(self, output_shape=(32, 32, 3)):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dense = Dense(8 * 8 * 128, activation=\"relu\")\n",
    "        self.reshape = Reshape((8, 8, 128))\n",
    "        self.convT1 = Conv2DTranspose(128, (4, 4), strides=2, padding=\"same\", activation=\"relu\")\n",
    "        self.convT2 = Conv2DTranspose(64, (4, 4), strides=2, padding=\"same\", activation=\"relu\")\n",
    "        self.convT3 = Conv2DTranspose(32, (4, 4), strides=2, padding=\"same\", activation=\"relu\")\n",
    "        self.convT4 = Conv2DTranspose(3, (3, 3), strides=1, padding=\"same\", activation=\"sigmoid\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense(inputs)\n",
    "        x = self.reshape(x)\n",
    "        x = self.convT1(x)\n",
    "        x = self.convT2(x)\n",
    "        x = self.convT3(x)\n",
    "        x = self.convT4(x)\n",
    "        return x\n",
    "\n",
    "class VQVAE(Model):\n",
    "    def __init__(self, encoder, decoder, quantizer):\n",
    "        super(VQVAE, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.quantizer = quantizer\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z = self.encoder(inputs)\n",
    "        quantized, commitment_loss = self.quantizer(z)\n",
    "        reconstructed = self.decoder(quantized)\n",
    "        return reconstructed, commitment_loss\n",
    "\n",
    "# Hyperparameters\n",
    "latent_dim = 64\n",
    "num_embeddings = 512\n",
    "embedding_dim = 64\n",
    "commitment_cost = 0.25\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "\n",
    "# Instantiate the components\n",
    "encoder = Encoder(latent_dim)\n",
    "decoder = Decoder()\n",
    "quantizer = VectorQuantizer(num_embeddings, embedding_dim, commitment_cost)\n",
    "vqvae = VQVAE(encoder, decoder, quantizer)\n",
    "\n",
    "# Optimizer and loss function\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "mse_loss = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    for batch in range(0, len(x_train), batch_size):\n",
    "        x_batch = x_train[batch:batch+batch_size]\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            reconstructed, commitment_loss = vqvae(x_batch)\n",
    "            reconstruction_loss = mse_loss(x_batch, reconstructed)\n",
    "            total_loss = reconstruction_loss + commitment_loss\n",
    "\n",
    "        grads = tape.gradient(total_loss, vqvae.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, vqvae.trainable_variables))\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss.numpy()}\")\n",
    "\n",
    "# Generate new images after training\n",
    "def generate_images(model, num_images=10):\n",
    "    noise = np.random.randn(num_images, 32, 32, 3)\n",
    "    reconstructed_images = model.decoder(noise)\n",
    "    return reconstructed_images\n",
    "\n",
    "generated_images = generate_images(vqvae)\n",
    "plt.imshow(generated_images[0])\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
