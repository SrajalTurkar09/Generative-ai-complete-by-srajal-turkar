{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Setup: Install Dependencies\n"
      ],
      "metadata": {
        "id": "zh2jE5Pnvksk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwPrw4SPvdfg",
        "outputId": "9ec3eed7-a88a-42e8-f873-a242a928cb49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.0)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow matplotlib numpy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Using Pix2Pix (Supervised Model)\n"
      ],
      "metadata": {
        "id": "lFLpuOfcvs6S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pix2Pix is ideal for paired datasets, such as edge-to-photo or day-to-night images.**\n",
        "\n",
        "```Step-by-Step Code for Pix2Pix:```\n",
        "\n",
        "    Load Dataset: For Pix2Pix, you can use a dataset like facade or maps. Below is an example for loading and preprocessing the Facades dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "nvpsJJIFwCZq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load and preprocess images\n",
        "def load_image(image_path):\n",
        "    img = load_img(image_path, target_size=(256, 256))  # Resize to 256x256\n",
        "    return img_to_array(img) / 127.5 - 1  # Normalize to [-1, 1]\n",
        "\n",
        "# Load paired dataset (facade dataset example)\n",
        "def load_dataset(path):\n",
        "    images = []\n",
        "    for filename in os.listdir(path):\n",
        "        img = load_image(os.path.join(path, filename))\n",
        "        images.append(img)\n",
        "    return np.array(images)\n",
        "\n",
        "# Example: Load Facades dataset\n",
        "real_images = load_dataset('/path/to/real_images')  # Target images (e.g., facade)\n",
        "input_images = load_dataset('/path/to/input_images')  # Input images (e.g., sketch)\n"
      ],
      "metadata": {
        "id": "pZ3rgcUgvpEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define the Pix2Pix Model:**\n",
        "\n",
        "    Use a U-Net architecture for the Generator.\n",
        ">\n",
        "    Use a PatchGAN architecture for the Discrimina"
      ],
      "metadata": {
        "id": "yfac6LrYvzeD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, Model\n",
        "\n",
        "# Generator (U-Net)\n",
        "def build_generator():\n",
        "    inputs = layers.Input(shape=[256, 256, 3])\n",
        "\n",
        "    # Downsampling\n",
        "    down1 = layers.Conv2D(64, 4, strides=2, padding='same')(inputs)\n",
        "    down1 = layers.LeakyReLU()(down1)\n",
        "\n",
        "    down2 = layers.Conv2D(128, 4, strides=2, padding='same')(down1)\n",
        "    down2 = layers.LeakyReLU()(down2)\n",
        "\n",
        "    # Bottleneck\n",
        "    bottleneck = layers.Conv2D(256, 4, strides=2, padding='same')(down2)\n",
        "    bottleneck = layers.LeakyReLU()(bottleneck)\n",
        "\n",
        "    # Upsampling\n",
        "    up1 = layers.Conv2DTranspose(128, 4, strides=2, padding='same')(bottleneck)\n",
        "    up1 = layers.ReLU()(up1)\n",
        "\n",
        "    up2 = layers.Conv2DTranspose(64, 4, strides=2, padding='same')(up1)\n",
        "    up2 = layers.ReLU()(up2)\n",
        "\n",
        "    outputs = layers.Conv2D(3, 4, padding='same', activation='tanh')(up2)\n",
        "\n",
        "    return Model(inputs, outputs)\n",
        "\n",
        "# Discriminator (PatchGAN)\n",
        "def build_discriminator():\n",
        "    inputs = layers.Input(shape=[256, 256, 3])\n",
        "\n",
        "    x = layers.Conv2D(64, 4, strides=2, padding='same')(inputs)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "\n",
        "    x = layers.Conv2D(128, 4, strides=2, padding='same')(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "\n",
        "    outputs = layers.Conv2D(1, 4, padding='same')(x)\n",
        "\n",
        "    return Model(inputs, outputs)\n",
        "\n",
        "# Build models\n",
        "generator = build_generator()\n",
        "discriminator = build_discriminator()\n"
      ],
      "metadata": {
        "id": "_DiIBgNnv5IG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compile and Train:**\n",
        "\n",
        "    Use Binary Crossentropy loss for both generator and discriminator."
      ],
      "metadata": {
        "id": "_BiN0pKNwQnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the discriminator\n",
        "discriminator.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Compile the generator with a GAN loss (combined generator and discriminator)\n",
        "generator.compile(optimizer='adam', loss='mae')\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(10000):  # Number of epochs\n",
        "    # Train discriminator with real and fake images\n",
        "    real = discriminator(real_images)\n",
        "    fake = discriminator(generator(input_images))\n",
        "\n",
        "    d_loss_real = discriminator.train_on_batch(real_images, np.ones_like(real))\n",
        "    d_loss_fake = discriminator.train_on_batch(generator(input_images), np.zeros_like(fake))\n",
        "\n",
        "    # Train generator to fool the discriminator\n",
        "    g_loss = generator.train_on_batch(input_images, real_images)  # Try to make fake images look real\n",
        "\n",
        "    # Print progress\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch {epoch}, D Loss Real: {d_loss_real}, D Loss Fake: {d_loss_fake}, G Loss: {g_loss}\")\n"
      ],
      "metadata": {
        "id": "V1xopgdHwUaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generate Output:**\n",
        "\n",
        "    Use the trained generator to generate images."
      ],
      "metadata": {
        "id": "Gl1JcX3iwYg8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Using CycleGAN (Unsupervised Model)\n",
        "\n",
        "    CycleGAN works with unpaired datasets, making it ideal for tasks like horse-to-zebra or photo enhancement.\n",
        "\n"
      ],
      "metadata": {
        "id": "EFpq6_i7wf4V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step-by-Step Code for CycleGAN:**\n",
        "\n",
        "    Load Dataset: Use datasets like horse2zebra or apple2orange.\n",
        "\n"
      ],
      "metadata": {
        "id": "aYGD5cj1wqCj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Load unpaired dataset\n",
        "def load_unpaired_images(path):\n",
        "    images = []\n",
        "    for filename in os.listdir(path):\n",
        "        img = load_image(os.path.join(path, filename))  # Load and preprocess image\n",
        "        images.append(img)\n",
        "    return np.array(images)\n",
        "\n",
        "# Load datasets\n",
        "horse_images = load_unpaired_images('/path/to/horse_images')\n",
        "zebra_images = load_unpaired_images('/path/to/zebra_images')\n"
      ],
      "metadata": {
        "id": "-GRwVb-DwcwV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}