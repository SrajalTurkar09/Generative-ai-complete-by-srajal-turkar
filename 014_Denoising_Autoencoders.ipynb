{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "r-cBJjLv4sLa",
        "outputId": "ef025a25-67dd-4ed8-ec8c-a435396b02a1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotADirectoryError",
          "evalue": "[Errno 20] Not a directory: '/content/wp4642409-naruto-manga-wallpapers.jpg'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-cd3c6ada6107>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Load your own images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mimage_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/wp4642409-naruto-manga-wallpapers.jpg'\u001b[0m  \u001b[0;31m# Change to your image folder path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_and_preprocess_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Add noise to the images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-cd3c6ada6107>\u001b[0m in \u001b[0;36mload_and_preprocess_images\u001b[0;34m(image_folder, img_size)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_and_preprocess_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'L'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Convert to grayscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: '/content/wp4642409-naruto-manga-wallpapers.jpg'"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# Function to load and preprocess your images\n",
        "def load_and_preprocess_images(image_folder, img_size=(28, 28)):\n",
        "    images = []\n",
        "    for img_name in os.listdir(image_folder):\n",
        "        img_path = os.path.join(image_folder, img_name)\n",
        "        img = Image.open(img_path).convert('L')  # Convert to grayscale\n",
        "        img = img.resize(img_size)  # Resize to img_size\n",
        "        img = np.array(img) / 255.0  # Normalize\n",
        "        images.append(img)\n",
        "    return np.array(images)\n",
        "\n",
        "# Load your own images\n",
        "image_folder = 'path/to/your/images'  # Change to your image folder path\n",
        "x_train = load_and_preprocess_images(image_folder)\n",
        "\n",
        "# Add noise to the images\n",
        "def add_noise(images):\n",
        "    noise_factor = 0.5\n",
        "    noisy_images = images + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=images.shape)\n",
        "    return np.clip(noisy_images, 0.0, 1.0)\n",
        "\n",
        "# Add noise to training images\n",
        "x_train_noisy = add_noise(x_train)\n",
        "\n",
        "# Build the Denoising Autoencoder model\n",
        "def build_denoising_autoencoder():\n",
        "    input_img = layers.Input(shape=(28, 28, 1))\n",
        "\n",
        "    # Encoder\n",
        "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "    x = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
        "    encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "    # Decoder\n",
        "    x = layers.Conv2DTranspose(16, (3, 3), activation='relu', padding='same')(encoded)\n",
        "    x = layers.UpSampling2D((2, 2))(x)\n",
        "    x = layers.Conv2DTranspose(32, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.UpSampling2D((2, 2))(x)\n",
        "    decoded = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "    autoencoder = models.Model(input_img, decoded)\n",
        "    return autoencoder\n",
        "\n",
        "# Reshape for the model\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)  # Ensure the shape is (num_samples, height, width, channels)\n",
        "x_train_noisy = x_train_noisy.reshape(-1, 28, 28, 1)  # Same reshaping for noisy images\n",
        "\n",
        "# Build the model\n",
        "autoencoder = build_denoising_autoencoder()\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Train the model\n",
        "autoencoder.fit(x_train_noisy, x_train, epochs=50, batch_size=128, validation_split=0.1)\n",
        "\n",
        "# Test the model with a sample\n",
        "decoded_images = autoencoder.predict(x_train_noisy)\n",
        "\n",
        "# Display results for the first few images\n",
        "n = 10  # Number of images to display\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # Noisy images\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_train_noisy[i].reshape(28, 28), cmap='gray')\n",
        "    plt.title(\"Noisy Image\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Denoised images\n",
        "    ax = plt.subplot(2, n, i + n + 1)\n",
        "    plt.imshow(decoded_images[i].reshape(28, 28), cmap='gray')\n",
        "    plt.title(\"Denoised Image\")\n",
        "    plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# Function to load and preprocess your images\n",
        "def load_and_preprocess_images(image_path, img_size=(28, 28)): # Changed image_folder to image_path\n",
        "    \"\"\"Loads and preprocesses a single image.\"\"\"\n",
        "    img = Image.open(image_path).convert('L')  # Convert to grayscale\n",
        "    img = img.resize(img_size)  # Resize to img_size\n",
        "    img = np.array(img) / 255.0  # Normalize\n",
        "    # Reshape for the model\n",
        "    img = img.reshape(1, 28, 28, 1) # Reshape to (1, 28, 28, 1)\n",
        "    return img\n",
        "\n",
        "# Load your image\n",
        "image_path = '/content/wp4642409-naruto-manga-wallpapers.jpg'  # Path to your image file\n",
        "x_train = load_and_preprocess_images(image_path) # Load and preprocess the single image\n",
        "\n",
        "\n",
        "# Add noise to the images\n",
        "def add_noise(images):\n",
        "    noise_factor = 0.5\n",
        "    noisy_images = images + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=images.shape)\n",
        "    return np.clip(noisy_images, 0.0, 1.0)\n",
        "\n",
        "# Add noise to training image\n",
        "x_train_noisy = add_noise(x_train)\n",
        "\n",
        "\n",
        "# Build the Denoising Autoencoder model\n",
        "def build_denoising_autoencoder():\n",
        "    input_img = layers.Input(shape=(28, 28, 1))\n",
        "\n",
        "    # Encoder\n",
        "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "    x = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
        "    encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "    # Decoder\n",
        "    x = layers.Conv2DTranspose(16, (3, 3), activation='relu', padding='same')(encoded)\n",
        "    x = layers.UpSampling2D((2, 2))(x)\n",
        "    x = layers.Conv2DTranspose(32, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.UpSampling2D((2, 2))(x)\n",
        "    decoded = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "    autoencoder = models.Model(input_img, decoded)\n",
        "    return autoencoder\n",
        "\n",
        "# Reshape for the model\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)  # Ensure the shape is (num_samples, height, width, channels)\n",
        "x_train_noisy = x_train_noisy.reshape(-1, 28, 28, 1)  # Same reshaping for noisy images\n",
        "\n",
        "# Build the model\n",
        "autoencoder = build_denoising_autoencoder()\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Train the model\n",
        "autoencoder.fit(x_train_noisy, x_train, epochs=50, batch_size=128, validation_split=0.1)\n",
        "\n",
        "# Test the model with a sample\n",
        "decoded_images = autoencoder.predict(x_train_noisy)\n",
        "\n",
        "# Display results for the first few images\n",
        "n = 10  # Number of images to display\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # Noisy images\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_train_noisy[i].reshape(28, 28), cmap='gray')\n",
        "    plt.title(\"Noisy Image\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Denoised images\n",
        "    ax = plt.subplot(2, n, i + n + 1)\n",
        "    plt.imshow(decoded_images[i].reshape(28, 28), cmap='gray')\n",
        "    plt.title(\"Denoised Image\")\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "7dUQE790_San",
        "outputId": "b5397688-8b16-4c3d-a599-5dcc985df997"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Training data contains 1 samples, which is not sufficient to split it into a validation and training set as specified by `validation_split=0.1`. Either provide more data, or a different value for the `validation_split` argument.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-e0376146c7bd>\u001b[0m in \u001b[0;36m<cell line: 62>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_noisy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;31m# Test the model with a sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/array_slicing.py\u001b[0m in \u001b[0;36mtrain_validation_split\u001b[0;34m(arrays, validation_split)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msplit_at\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0msplit_at\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mbatch_dim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0;34mf\"Training data contains {batch_dim} samples, which is not \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0;34m\"sufficient to split it into a validation and training set as \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Training data contains 1 samples, which is not sufficient to split it into a validation and training set as specified by `validation_split=0.1`. Either provide more data, or a different value for the `validation_split` argument."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# Function to load and preprocess your images\n",
        "def load_and_preprocess_images(image_path, img_size=(28, 28)): # Changed image_folder to image_path\n",
        "    \"\"\"Loads and preprocesses a single image.\"\"\"\n",
        "    img = Image.open(image_path).convert('L')  # Convert to grayscale\n",
        "    img = img.resize(img_size)  # Resize to img_size\n",
        "    img = np.array(img) / 255.0  # Normalize\n",
        "    # Reshape for the model\n",
        "    img = img.reshape(1, 28, 28, 1) # Reshape to (1, 28, 28, 1)\n",
        "    return img\n",
        "\n",
        "# Load your image\n",
        "image_path = '/content/wp4642409-naruto-manga-wallpapers.jpg'  # Path to your image file\n",
        "x_train = load_and_preprocess_images(image_path) # Load and preprocess the single image\n",
        "\n",
        "\n",
        "# Add noise to the images\n",
        "def add_noise(images):\n",
        "    noise_factor = 0.5\n",
        "    noisy_images = images + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=images.shape)\n",
        "    return np.clip(noisy_images, 0.0, 1.0)\n",
        "\n",
        "# Add noise to training image\n",
        "x_train_noisy = add_noise(x_train)\n",
        "\n",
        "\n",
        "# Build the Denoising Autoencoder model\n",
        "def build_denoising_autoencoder():\n",
        "    input_img = layers.Input(shape=(28, 28, 1))\n",
        "\n",
        "    # Encoder\n",
        "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "    x = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
        "    encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "    # Decoder\n",
        "    x = layers.Conv2DTranspose(16, (3, 3), activation='relu', padding='same')(encoded)\n",
        "    x = layers.UpSampling2D((2, 2))(x)\n",
        "    x = layers.Conv2DTranspose(32, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.UpSampling2D((2, 2))(x)\n",
        "    decoded = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "    autoencoder = models.Model(input_img, decoded)\n",
        "    return autoencoder\n",
        "\n",
        "\n",
        "# Build the model\n",
        "autoencoder = build_denoising_autoencoder()\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Train the model without validation split\n",
        "autoencoder.fit(x_train_noisy, x_train, epochs=50, batch_size=128) # Removed validation_split\n",
        "\n",
        "# Test the model with a sample\n",
        "decoded_images = autoencoder.predict(x_train_noisy)\n",
        "\n",
        "# Display results\n",
        "plt.figure(figsize=(20, 4))\n",
        "\n",
        "# Noisy image\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(x_train_noisy.reshape(28, 28), cmap='gray')\n",
        "plt.title(\"Noisy Image\")\n",
        "plt.axis('off')\n",
        "\n",
        "# Denoised image\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(decoded_images.reshape(28, 28), cmap='gray')\n",
        "plt.title(\"Denoised Image\")\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WOUATr1T_7RU",
        "outputId": "b6a68064-f67f-41a3-aa19-f5b0d04b90b1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.6982\n",
            "Epoch 2/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.6949\n",
            "Epoch 3/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.6926\n",
            "Epoch 4/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.6909\n",
            "Epoch 5/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.6894\n",
            "Epoch 6/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.6879\n",
            "Epoch 7/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.6865\n",
            "Epoch 8/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.6851\n",
            "Epoch 9/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.6838\n",
            "Epoch 10/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.6825\n",
            "Epoch 11/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.6813\n",
            "Epoch 12/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.6797\n",
            "Epoch 13/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.6778\n",
            "Epoch 14/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.6760\n",
            "Epoch 15/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.6743\n",
            "Epoch 16/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.6726\n",
            "Epoch 17/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.6707\n",
            "Epoch 18/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.6685\n",
            "Epoch 19/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.6660\n",
            "Epoch 20/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.6634\n",
            "Epoch 21/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.6613\n",
            "Epoch 22/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.6600\n",
            "Epoch 23/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.6596\n",
            "Epoch 24/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.6598\n",
            "Epoch 25/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.6599\n",
            "Epoch 26/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.6595\n",
            "Epoch 27/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.6584\n",
            "Epoch 28/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.6570\n",
            "Epoch 29/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.6556\n",
            "Epoch 30/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.6545\n",
            "Epoch 31/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.6537\n",
            "Epoch 32/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.6531\n",
            "Epoch 33/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.6525\n",
            "Epoch 34/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.6518\n",
            "Epoch 35/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.6510\n",
            "Epoch 36/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.6502\n",
            "Epoch 37/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.6493\n",
            "Epoch 38/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.6486\n",
            "Epoch 39/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.6479\n",
            "Epoch 40/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.6472\n",
            "Epoch 41/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.6467\n",
            "Epoch 42/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.6461\n",
            "Epoch 43/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.6456\n",
            "Epoch 44/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.6451\n",
            "Epoch 45/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.6445\n",
            "Epoch 46/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.6440\n",
            "Epoch 47/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.6435\n",
            "Epoch 48/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.6431\n",
            "Epoch 49/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.6428\n",
            "Epoch 50/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.6425\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9q6oh8gp_7eF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}