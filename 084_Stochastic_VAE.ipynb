{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LA0IUps_poo6",
        "outputId": "cf4385b7-54f8-4ec7-a0e3-910d19605a2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Step 0, Loss: 547.7608032226562, Reconstruction Loss: 547.7565307617188, KL Loss: 0.0042507704347372055\n",
            "Epoch 1, Step 100, Loss: 205.88565063476562, Reconstruction Loss: 202.38919067382812, KL Loss: 3.496459722518921\n",
            "Epoch 1, Step 200, Loss: 186.09036254882812, Reconstruction Loss: 181.99462890625, KL Loss: 4.095739841461182\n",
            "Epoch 1, Step 300, Loss: 180.66693115234375, Reconstruction Loss: 176.41168212890625, KL Loss: 4.255244731903076\n",
            "Epoch 1, Step 400, Loss: 185.08848571777344, Reconstruction Loss: 181.09837341308594, KL Loss: 3.9901185035705566\n",
            "Epoch 2, Step 0, Loss: 178.08084106445312, Reconstruction Loss: 173.9115447998047, KL Loss: 4.169301509857178\n",
            "Epoch 2, Step 100, Loss: 173.98648071289062, Reconstruction Loss: 169.93731689453125, KL Loss: 4.049159049987793\n",
            "Epoch 2, Step 200, Loss: 183.92230224609375, Reconstruction Loss: 179.951904296875, KL Loss: 3.9703922271728516\n",
            "Epoch 2, Step 300, Loss: 180.25979614257812, Reconstruction Loss: 176.33839416503906, KL Loss: 3.921402931213379\n",
            "Epoch 2, Step 400, Loss: 177.66006469726562, Reconstruction Loss: 173.49725341796875, KL Loss: 4.16280460357666\n",
            "Epoch 3, Step 0, Loss: 178.71041870117188, Reconstruction Loss: 174.19729614257812, KL Loss: 4.51312255859375\n",
            "Epoch 3, Step 100, Loss: 186.0454864501953, Reconstruction Loss: 181.73974609375, KL Loss: 4.305742263793945\n",
            "Epoch 3, Step 200, Loss: 182.65328979492188, Reconstruction Loss: 178.42904663085938, KL Loss: 4.224245071411133\n",
            "Epoch 3, Step 300, Loss: 172.6492156982422, Reconstruction Loss: 168.30419921875, KL Loss: 4.345015525817871\n",
            "Epoch 3, Step 400, Loss: 176.6154327392578, Reconstruction Loss: 172.71200561523438, KL Loss: 3.9034223556518555\n",
            "Epoch 4, Step 0, Loss: 178.49191284179688, Reconstruction Loss: 173.9473876953125, KL Loss: 4.544517517089844\n",
            "Epoch 4, Step 100, Loss: 177.66708374023438, Reconstruction Loss: 173.35617065429688, KL Loss: 4.31091833114624\n",
            "Epoch 4, Step 200, Loss: 172.66195678710938, Reconstruction Loss: 168.22842407226562, KL Loss: 4.433535099029541\n",
            "Epoch 4, Step 300, Loss: 174.23483276367188, Reconstruction Loss: 169.6520233154297, KL Loss: 4.58281135559082\n",
            "Epoch 4, Step 400, Loss: 174.71142578125, Reconstruction Loss: 170.36209106445312, KL Loss: 4.349334716796875\n",
            "Epoch 5, Step 0, Loss: 172.984375, Reconstruction Loss: 168.8377685546875, KL Loss: 4.146601676940918\n",
            "Epoch 5, Step 100, Loss: 175.99072265625, Reconstruction Loss: 171.53958129882812, KL Loss: 4.45114803314209\n",
            "Epoch 5, Step 200, Loss: 169.2616424560547, Reconstruction Loss: 164.44598388671875, KL Loss: 4.8156585693359375\n",
            "Epoch 5, Step 300, Loss: 177.5112762451172, Reconstruction Loss: 172.8491668701172, KL Loss: 4.662115097045898\n",
            "Epoch 5, Step 400, Loss: 177.90689086914062, Reconstruction Loss: 173.2735137939453, KL Loss: 4.633371353149414\n",
            "Epoch 6, Step 0, Loss: 175.97003173828125, Reconstruction Loss: 171.65347290039062, KL Loss: 4.31655216217041\n",
            "Epoch 6, Step 100, Loss: 175.06431579589844, Reconstruction Loss: 170.37139892578125, KL Loss: 4.692910194396973\n",
            "Epoch 6, Step 200, Loss: 174.0028533935547, Reconstruction Loss: 169.4249267578125, KL Loss: 4.5779218673706055\n",
            "Epoch 6, Step 300, Loss: 180.5391082763672, Reconstruction Loss: 176.11476135253906, KL Loss: 4.424340724945068\n",
            "Epoch 6, Step 400, Loss: 169.2436065673828, Reconstruction Loss: 164.93746948242188, KL Loss: 4.3061299324035645\n",
            "Epoch 7, Step 0, Loss: 177.32891845703125, Reconstruction Loss: 172.89315795898438, KL Loss: 4.435763835906982\n",
            "Epoch 7, Step 100, Loss: 168.6875457763672, Reconstruction Loss: 164.20217895507812, KL Loss: 4.48536491394043\n",
            "Epoch 7, Step 200, Loss: 173.98146057128906, Reconstruction Loss: 169.3824462890625, KL Loss: 4.599017143249512\n",
            "Epoch 7, Step 300, Loss: 176.29815673828125, Reconstruction Loss: 171.8515167236328, KL Loss: 4.4466352462768555\n",
            "Epoch 7, Step 400, Loss: 168.4159393310547, Reconstruction Loss: 163.52157592773438, KL Loss: 4.894366264343262\n",
            "Epoch 8, Step 0, Loss: 176.07960510253906, Reconstruction Loss: 171.7001953125, KL Loss: 4.379411220550537\n",
            "Epoch 8, Step 100, Loss: 172.17137145996094, Reconstruction Loss: 167.392578125, KL Loss: 4.778796195983887\n",
            "Epoch 8, Step 200, Loss: 180.08412170410156, Reconstruction Loss: 175.212158203125, KL Loss: 4.8719682693481445\n",
            "Epoch 8, Step 300, Loss: 173.666015625, Reconstruction Loss: 169.13043212890625, KL Loss: 4.535586833953857\n",
            "Epoch 8, Step 400, Loss: 175.1383514404297, Reconstruction Loss: 170.58123779296875, KL Loss: 4.5571160316467285\n",
            "Epoch 9, Step 0, Loss: 171.04818725585938, Reconstruction Loss: 166.54356384277344, KL Loss: 4.504627227783203\n",
            "Epoch 9, Step 100, Loss: 180.23704528808594, Reconstruction Loss: 175.4920196533203, KL Loss: 4.745021820068359\n",
            "Epoch 9, Step 200, Loss: 181.97642517089844, Reconstruction Loss: 177.56350708007812, KL Loss: 4.412917613983154\n",
            "Epoch 9, Step 300, Loss: 184.71478271484375, Reconstruction Loss: 179.92910766601562, KL Loss: 4.785682201385498\n",
            "Epoch 9, Step 400, Loss: 168.7041778564453, Reconstruction Loss: 163.85992431640625, KL Loss: 4.844246864318848\n",
            "Epoch 10, Step 0, Loss: 176.06967163085938, Reconstruction Loss: 171.48294067382812, KL Loss: 4.58673095703125\n",
            "Epoch 10, Step 100, Loss: 177.75408935546875, Reconstruction Loss: 173.04940795898438, KL Loss: 4.70468807220459\n",
            "Epoch 10, Step 200, Loss: 179.7240753173828, Reconstruction Loss: 175.00572204589844, KL Loss: 4.718353271484375\n",
            "Epoch 10, Step 300, Loss: 176.22547912597656, Reconstruction Loss: 171.6195068359375, KL Loss: 4.605971336364746\n",
            "Epoch 10, Step 400, Loss: 176.72781372070312, Reconstruction Loss: 172.15220642089844, KL Loss: 4.57560920715332\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Step-by-Step Guide to Implementing an SVAE\n",
        "\n",
        "# Import Necessary Libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# Load the Dataset\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "\n",
        "# Define the Encoder Network\n",
        "class Encoder(models.Model):\n",
        "    def __init__(self, latent_dim):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.conv1 = layers.Conv2D(32, 3, activation='relu', padding='same')\n",
        "        self.conv2 = layers.Conv2D(64, 3, activation='relu', padding='same')\n",
        "        self.flatten = layers.Flatten()\n",
        "        self.fc_mu = layers.Dense(latent_dim)\n",
        "        self.fc_log_var = layers.Dense(latent_dim)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.conv2(x)\n",
        "        x = self.flatten(x)\n",
        "        mu = self.fc_mu(x)\n",
        "        log_var = self.fc_log_var(x)\n",
        "        return mu, log_var\n",
        "\n",
        "# Define the Reparameterization Trick\n",
        "def reparameterize(mu, log_var):\n",
        "    epsilon = tf.random.normal(shape=tf.shape(mu))\n",
        "    z = mu + tf.exp(0.5 * log_var) * epsilon\n",
        "    return z\n",
        "\n",
        "# Define the Decoder Network\n",
        "class Decoder(models.Model):\n",
        "    def __init__(self, original_shape):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.fc = layers.Dense(7 * 7 * 64, activation='relu')\n",
        "        self.reshape = layers.Reshape((7, 7, 64))\n",
        "        self.deconv1 = layers.Conv2DTranspose(64, 3, activation='relu', padding='same')\n",
        "        self.deconv2 = layers.Conv2DTranspose(32, 3, activation='relu', padding='same')\n",
        "        self.deconv3 = layers.Conv2DTranspose(1, 3, activation='sigmoid', padding='same')  # Final output layer\n",
        "        self.resize = layers.Resizing(28, 28)  # Resize output to match the input image size (28x28)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.fc(inputs)\n",
        "        x = self.reshape(x)\n",
        "        x = self.deconv1(x)\n",
        "        x = self.deconv2(x)\n",
        "        x = self.deconv3(x)\n",
        "        x = self.resize(x)  # Ensure the final output size is 28x28\n",
        "        return x\n",
        "\n",
        "\n",
        "# Define the Loss Function\n",
        "def compute_loss(x, x_reconstructed, mu, log_var):\n",
        "    reconstruction_loss = tf.reduce_mean(tf.reduce_sum(\n",
        "        tf.keras.losses.binary_crossentropy(x, x_reconstructed), axis=[1, 2]))\n",
        "    kl_loss = -0.5 * tf.reduce_mean(tf.reduce_sum(1 + log_var - tf.square(mu) - tf.exp(log_var), axis=1))\n",
        "    total_loss = reconstruction_loss + kl_loss\n",
        "    return total_loss, reconstruction_loss, kl_loss\n",
        "\n",
        "# Build the Complete SVAE Model\n",
        "class SVAE(models.Model):\n",
        "    def __init__(self, latent_dim, original_shape):\n",
        "        super(SVAE, self).__init__()\n",
        "        self.encoder = Encoder(latent_dim)\n",
        "        self.decoder = Decoder(original_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        mu, log_var = self.encoder(inputs)\n",
        "        z = reparameterize(mu, log_var)\n",
        "        reconstructed = self.decoder(z)\n",
        "        return reconstructed, mu, log_var\n",
        "\n",
        "# Set hyperparameters\n",
        "latent_dim = 2\n",
        "epochs = 10\n",
        "batch_size = 128\n",
        "\n",
        "# Prepare the dataset\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(x_train).shuffle(60000).batch(batch_size)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices(x_test).batch(batch_size)\n",
        "\n",
        "# Initialize the model\n",
        "model = SVAE(latent_dim, original_shape=(28, 28, 1))\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "# Training step\n",
        "@tf.function\n",
        "def train_step(x):\n",
        "    with tf.GradientTape() as tape:\n",
        "        x_reconstructed, mu, log_var = model(x)\n",
        "        loss, reconstruction_loss, kl_loss = compute_loss(x, x_reconstructed, mu, log_var)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    return loss, reconstruction_loss, kl_loss\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    for step, x_batch in enumerate(train_dataset):\n",
        "        loss, reconstruction_loss, kl_loss = train_step(x_batch)\n",
        "        if step % 100 == 0:\n",
        "            print(f\"Epoch {epoch+1}, Step {step}, Loss: {loss}, Reconstruction Loss: {reconstruction_loss}, KL Loss: {kl_loss}\")\n",
        "\n",
        "# Generate samples from the latent space and visualize\n",
        "def generate_samples(model, num_samples=10):\n",
        "    z = tf.random.normal([num_samples, latent_dim])\n",
        "    samples = model.decoder(z)\n",
        "    return samples\n",
        "\n",
        "# Generate and plot some samples\n",
        "samples = generate_samples(model)\n",
        "for i in range(10):\n",
        "    plt.subplot(2, 5, i + 1)\n",
        "    plt.imshow(samples[i].numpy().reshape(28, 28), cmap='gray')\n",
        "    plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's create a downloadable .ipynb file with the provided code for the 3D Object Generation with VAEs project\n",
        "\n",
        "from IPython.display import FileLink\n",
        "\n",
        "# Define the content of the notebook\n",
        "notebook_content = \"\"\"\n",
        "{\n",
        " \"cells\": [\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 1,\n",
        "   \"id\": \"1ab2e95e\",\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"import tensorflow as tf\\\\n\",\n",
        "    \"from tensorflow.keras import layers, models\\\\n\",\n",
        "    \"import numpy as np\\\\n\",\n",
        "    \"import matplotlib.pyplot as plt\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 2,\n",
        "   \"id\": \"2ba6a351\",\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Placeholder for dataset loading (using synthetic data for simplicity)\\\\n\",\n",
        "    \"def generate_synthetic_data(num_samples, grid_size=32):\\\\n\",\n",
        "    \"    return np.random.randint(0, 2, size=(num_samples, grid_size, grid_size, grid_size))\\\\n\",\n",
        "    \"\\\\n\",\n",
        "    \"# Example: Generate 1000 samples of 3D voxel grids\\\\n\",\n",
        "    \"X_train = generate_synthetic_data(1000)\\\\n\",\n",
        "    \"X_train = X_train.astype('float32')  # Normalize the data\\\\n\",\n",
        "    \"\\\\n\",\n",
        "    \"# Visualize a sample voxel grid\\\\n\",\n",
        "    \"fig = plt.figure()\\\\n\",\n",
        "    \"ax = fig.add_subplot(111, projection='3d')\\\\n\",\n",
        "    \"ax.voxels(X_train[0], edgecolors='k')\\\\n\",\n",
        "    \"plt.show()\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 3,\n",
        "   \"id\": \"e1fb0e76\",\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Encoder network\\\\n\",\n",
        "    \"def build_encoder(latent_dim=64, input_shape=(32, 32, 32, 1)):\\\\n\",\n",
        "    \"    inputs = layers.Input(shape=input_shape)\\\\n\",\n",
        "    \"    x = layers.Conv3D(32, 3, activation='relu', strides=2, padding='same')(inputs)\\\\n\",\n",
        "    \"    x = layers.Conv3D(64, 3, activation='relu', strides=2, padding='same')(x)\\\\n\",\n",
        "    \"    x = layers.Flatten()(x)\\\\n\",\n",
        "    \"    x = layers.Dense(128, activation='relu')(x)\\\\n\",\n",
        "    \"    \\\\n\",\n",
        "    \"    # Latent space (mean and variance)\\\\n\",\n",
        "    \"    z_mean = layers.Dense(latent_dim, name='z_mean')(x)\\\\n\",\n",
        "    \"    z_log_var = layers.Dense(latent_dim, name='z_log_var')(x)\\\\n\",\n",
        "    \"    \\\\n\",\n",
        "    \"    return models.Model(inputs, [z_mean, z_log_var])\\\\n\",\n",
        "    \"\\\\n\",\n",
        "    \"# Decoder network\\\\n\",\n",
        "    \"def build_decoder(latent_dim=64, output_shape=(32, 32, 32, 1)):\\\\n\",\n",
        "    \"    latent_inputs = layers.Input(shape=(latent_dim,))\\\\n\",\n",
        "    \"    x = layers.Dense(128, activation='relu')(latent_inputs)\\\\n\",\n",
        "    \"    x = layers.Dense(8 * 8 * 8 * 64, activation='relu')(x)\\\\n\",\n",
        "    \"    x = layers.Reshape((8, 8, 8, 64))(x)\\\\n\",\n",
        "    \"    x = layers.Conv3DTranspose(64, 3, activation='relu', strides=2, padding='same')(x)\\\\n\",\n",
        "    \"    x = layers.Conv3DTranspose(32, 3, activation='relu', strides=2, padding='same')(x)\\\\n\",\n",
        "    \"    x = layers.Conv3DTranspose(1, 3, activation='sigmoid', padding='same')(x)\\\\n\",\n",
        "    \"    \\\\n\",\n",
        "    \"    return models.Model(latent_inputs, x)\\\\n\",\n",
        "    \"\\\\n\",\n",
        "    \"# VAE Model combining Encoder and Decoder\\\\n\",\n",
        "    \"latent_dim = 64\\\\n\",\n",
        "    \"encoder = build_encoder(latent_dim)\\\\n\",\n",
        "    \"decoder = build_decoder(latent_dim)\\\\n\",\n",
        "    \"\\\\n\",\n",
        "    \"# Sampling function for reparameterization trick\\\\n\",\n",
        "    \"def sampling(args):\\\\n\",\n",
        "    \"    z_mean, z_log_var = args\\\\n\",\n",
        "    \"    batch = tf.shape(z_mean)[0]\\\\n\",\n",
        "    \"    dim = tf.shape(z_mean)[1]\\\\n\",\n",
        "    \"    epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\\\\n\",\n",
        "    \"    return z_mean + tf.exp(0.5 * z_log_var) * epsilon\\\\n\",\n",
        "    \"\\\\n\",\n",
        "    \"# Define the VAE model\\\\n\",\n",
        "    \"inputs = layers.Input(shape=(32, 32, 32, 1))\\\\n\",\n",
        "    \"z_mean, z_log_var = encoder(inputs)\\\\n\",\n",
        "    \"z = layers.Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\\\\n\",\n",
        "    \"decoded = decoder(z)\\\\n\",\n",
        "    \"\\\\n\",\n",
        "    \"vae = models.Model(inputs, decoded)\\\\n\",\n",
        "    \"\\\\n\",\n",
        "    \"# Loss function: Reconstruction + KL Divergence\\\\n\",\n",
        "    \"def vae_loss(y_true, y_pred):\\\\n\",\n",
        "    \"    reconstruction_loss = tf.reduce_mean(tf.reduce_sum(tf.keras.losses.binary_crossentropy(y_true, y_pred), axis=(1, 2, 3)))\\\\n\",\n",
        "    \"    kl_loss = - 0.5 * tf.reduce_mean(tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=1))\\\\n\",\n",
        "    \"    return reconstruction_loss + kl_loss\\\\n\",\n",
        "    \"\\\\n\",\n",
        "    \"# Compile the model\\\\n\",\n",
        "    \"vae.compile(optimizer='adam', loss=vae_loss)\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 4,\n",
        "   \"id\": \"5b2bb270\",\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Train the VAE\\\\n\",\n",
        "    \"vae.fit(X_train, X_train, epochs=50, batch_size=32)\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 5,\n",
        "   \"id\": \"dbb4c3d2\",\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Generate and visualize new 3D objects\\\\n\",\n",
        "    \"def generate_3d_objects(decoder, latent_dim, num_samples=5):\\\\n\",\n",
        "    \"    z_samples = np.random.normal(size=(num_samples, latent_dim))\\\\n\",\n",
        "    \"    generated_3d_objects = decoder.predict(z_samples)\\\\n\",\n",
        "    \"    return generated_3d_objects\\\\n\",\n",
        "    \"\\\\n\",\n",
        "    \"# Generate and visualize new 3D objects\\\\n\",\n",
        "    \"generated_objects = generate_3d_objects(decoder, latent_dim)\\\\n\",\n",
        "    \"\\\\n\",\n",
        "    \"# Visualize the first generated object\\\\n\",\n",
        "    \"fig = plt.figure()\\\\n\",\n",
        "    \"ax = fig.add_subplot(111, projection='3d')\\\\n\",\n",
        "    \"ax.voxels(generated_objects[0].reshape(32, 32, 32), edgecolors='k')\\\\n\",\n",
        "    \"plt.show()\"\n",
        "   ]\n",
        "  }\n",
        " ],\n",
        " \"metadata\": {\n",
        "  \"kernelspec\": {\n",
        "   \"display_name\": \"Python 3\",\n",
        "   \"language\": \"python\",\n",
        "   \"name\": \"python3\"\n",
        "  },\n",
        "  \"language_info\": {\n",
        "   \"codemirror_mode\": {\n",
        "    \"name\": \"ipython\",\n",
        "    \"version\": 3\n",
        "   },\n",
        "   \"file_extension\": \".ipynb\",\n",
        "   \"mimetype\": \"text/x-python\",\n",
        "   \"name\": \"python\",\n",
        "   \"nbconvert_exporter\": \"python\",\n",
        "   \"version\": \"3.9.7\"\n",
        "  }\n",
        " },\n",
        " \"nbformat\": 4,\n",
        " \"nbformat_minor\": 5\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Write the content to a .ipynb file\n",
        "file_path = \"3D_Object_Generation_with_VAEs.ipynb\"\n",
        "with open(file_path, \"w\") as f:\n",
        "    f.write(notebook_content)\n",
        "\n",
        "# Provide the link to download the file\n",
        "FileLink(file_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "FhfprW9lpqWO",
        "outputId": "6804ad49-8482-48d0-f392-a41c42c55e10"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "/content/3D_Object_Generation_with_VAEs.ipynb"
            ],
            "text/html": [
              "<a href='3D_Object_Generation_with_VAEs.ipynb' target='_blank'>3D_Object_Generation_with_VAEs.ipynb</a><br>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cZiHDsgOyenO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}