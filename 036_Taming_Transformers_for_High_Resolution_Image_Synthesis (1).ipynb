{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from transformers import TFGPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "# Define the VQ-VAE encoder\n",
        "def encoder_vqvae(inputs, embedding_dim=64):\n",
        "    # Apply a series of convolutional layers to encode the input images\n",
        "    x = tf.keras.layers.Conv2D(128, kernel_size=4, strides=2, padding='same', activation='relu')(inputs)\n",
        "    x = tf.keras.layers.Conv2D(embedding_dim, kernel_size=4, strides=2, padding='same')(x)\n",
        "    return x  # Returns encoded outputs with shape (batch_size, 8, 8, embedding_dim)\n",
        "\n",
        "# Quantization function to map continuous embeddings to discrete tokens\n",
        "def quantize(encoded_outputs, embeddings):\n",
        "    # Reshape the encoded outputs for distance calculation\n",
        "    flat_outputs = tf.reshape(encoded_outputs, [-1, encoded_outputs.shape[-1]])\n",
        "    # Calculate distances between the outputs and embeddings\n",
        "    distances = tf.norm(flat_outputs[:, None] - embeddings[None, :], axis=-1)\n",
        "    # Get the indices of the closest embeddings\n",
        "    indices = tf.argmin(distances, axis=-1)\n",
        "    # Map indices to the quantized embeddings\n",
        "    quantized = tf.nn.embedding_lookup(embeddings, indices)\n",
        "    quantized = tf.reshape(quantized, tf.shape(encoded_outputs))  # Reshape to original encoded shape\n",
        "    return quantized, indices\n",
        "\n",
        "# Define the VQ-VAE decoder\n",
        "def decoder_vqvae(quantized):\n",
        "    # Apply a series of transposed convolutional layers to decode the embeddings\n",
        "    x = tf.keras.layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding='same', activation='relu')(quantized)\n",
        "    x = tf.keras.layers.Conv2DTranspose(3, kernel_size=4, strides=2, padding='same', activation='sigmoid')(x)\n",
        "    return x  # Returns the reconstructed images\n",
        "\n",
        "# Initialize embeddings and model input\n",
        "num_embeddings = 512\n",
        "embedding_dim = 64\n",
        "embeddings = tf.Variable(tf.random.normal([num_embeddings, embedding_dim]), name=\"vqvae_embeddings\")\n",
        "inputs = tf.keras.Input(shape=(32, 32, 3))  # Input shape for CIFAR-10 images\n",
        "\n",
        "# Encode, quantize, and decode the images\n",
        "encoded = encoder_vqvae(inputs, embedding_dim)\n",
        "quantized, token_indices = quantize(encoded, embeddings)\n",
        "reconstructed = decoder_vqvae(quantized)\n",
        "\n",
        "# Define the VQ-VAE model\n",
        "vqvae_model = tf.keras.Model(inputs, reconstructed)\n",
        "vqvae_model.summary()  # Print the model summary\n",
        "\n",
        "# Load the pretrained GPT-2 model and tokenizer\n",
        "transformer_model = TFGPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "\n",
        "# Helper function to encode tokens for transformer input\n",
        "def encode_tokens_for_transformer(indices):\n",
        "    # Flatten the indices and convert them to string representation\n",
        "    indices_flat = tf.reshape(indices, [-1]).numpy()\n",
        "    # Convert the indices to a string and encode\n",
        "    token_ids = tokenizer.encode(\" \".join(map(str, indices_flat)), return_tensors=\"tf\")\n",
        "    return token_ids  # Return token IDs for the transformer\n",
        "\n",
        "# Load and normalize sample data\n",
        "(train_images, _), _ = tf.keras.datasets.cifar10.load_data()\n",
        "train_images = train_images.astype(\"float32\") / 255.0  # Normalize images to [0, 1]\n",
        "\n",
        "# Training setup\n",
        "batch_size = 32\n",
        "epochs = 5\n",
        "optimizer = tf.keras.optimizers.Adam(1e-3)\n",
        "\n",
        "# Training loop for VQ-VAE\n",
        "for epoch in range(epochs):\n",
        "    for i in range(0, len(train_images), batch_size):\n",
        "        imgs = train_images[i:i + batch_size]\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Forward pass through the VQ-VAE\n",
        "            encoded_batch = encoder_vqvae(imgs, embedding_dim)\n",
        "            quantized_batch, indices_batch = quantize(encoded_batch, embeddings)\n",
        "            recon_imgs = decoder_vqvae(quantized_batch)\n",
        "            # Calculate reconstruction loss\n",
        "            reconstruction_loss = tf.reduce_mean(tf.losses.mean_squared_error(imgs, recon_imgs))\n",
        "\n",
        "        # Backpropagation\n",
        "        grads = tape.gradient(reconstruction_loss, vqvae_model.trainable_weights + [embeddings])\n",
        "        optimizer.apply_gradients(zip(grads, vqvae_model.trainable_weights + [embeddings]))\n",
        "\n",
        "        # Prepare input tokens for the transformer model\n",
        "        input_tokens = encode_tokens_for_transformer(indices_batch)\n",
        "\n",
        "        # Ensure that input_tokens has the correct shape for the transformer model\n",
        "        print(f\"Input tokens shape: {input_tokens.shape}\")  # Debugging statement\n",
        "\n",
        "        try:\n",
        "            # Generate tokens from the transformer model\n",
        "            generated_sequence = transformer_model.generate(input_tokens, max_length=100)\n",
        "            print(f\"Epoch {epoch+1}, Batch {i // batch_size + 1}, Reconstruction Loss: {reconstruction_loss:.4f}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error during token generation: {e}\")\n",
        "            continue  # Skip to the next batch on error\n",
        "\n",
        "# Function to generate a new image from the transformer\n",
        "def generate_image_from_transformer():\n",
        "    input_tokens = tf.constant([[transformer_model.config.bos_token_id]])  # Start with BOS token\n",
        "    generated_sequence = transformer_model.generate(input_tokens, max_length=64)\n",
        "    indices_generated = [int(idx) for idx in tokenizer.decode(generated_sequence[0]).split()]\n",
        "    # Reshape the generated indices for quantization\n",
        "    indices_generated = tf.reshape(indices_generated, (1, 8, 8))\n",
        "    quantized_generated = tf.nn.embedding_lookup(embeddings, indices_generated)  # Quantize\n",
        "    generated_image = decoder_vqvae(quantized_generated)  # Decode to get the final image\n",
        "    return generated_image\n",
        "\n",
        "# Display the generated image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "new_image = generate_image_from_transformer()\n",
        "plt.imshow(new_image[0])  # Show the generated image\n",
        "plt.axis('off')  # Turn off axes\n",
        "plt.show()  # Display the image\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAiUD2Fd8Zpt",
        "outputId": "9096cc91-4467-447e-9941-7343c0f0a983"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_7), but are not present in its tracked objects:   <tf.Variable 'vqvae_embeddings:0' shape=(512, 64) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_8 (InputLayer)        [(None, 32, 32, 3)]          0         []                            \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)          (None, 16, 16, 128)          6272      ['input_8[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)          (None, 8, 8, 64)             131136    ['conv2d_22[0][0]']           \n",
            "                                                                                                  \n",
            " tf.reshape_14 (TFOpLambda)  (None, 64)                   0         ['conv2d_23[0][0]']           \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_7  (None, 1, 64)                0         ['tf.reshape_14[0][0]']       \n",
            "  (SlicingOpLambda)                                                                               \n",
            "                                                                                                  \n",
            " tf.math.subtract_7 (TFOpLa  (None, 512, 64)              0         ['tf.__operators__.getitem_7[0\n",
            " mbda)                                                              ][0]']                        \n",
            "                                                                                                  \n",
            " tf.compat.v1.norm_7 (TFOpL  (None, 512)                  0         ['tf.math.subtract_7[0][0]']  \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.argmin_7 (TFOpLamb  (None,)                      0         ['tf.compat.v1.norm_7[0][0]'] \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.compat.v1.nn.embedding_  (None, 64)                   0         ['tf.math.argmin_7[0][0]']    \n",
            " lookup_7 (TFOpLambda)                                                                            \n",
            "                                                                                                  \n",
            " tf.compat.v1.shape_6 (TFOp  (4,)                         0         ['conv2d_23[0][0]']           \n",
            " Lambda)                                                                                          \n",
            "                                                                                                  \n",
            " tf.reshape_15 (TFOpLambda)  (None, 8, 8, 64)             0         ['tf.compat.v1.nn.embedding_lo\n",
            "                                                                    okup_7[0][0]',                \n",
            "                                                                     'tf.compat.v1.shape_6[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_transpose_20 (Conv2  (None, 16, 16, 128)          131200    ['tf.reshape_15[0][0]']       \n",
            " DTranspose)                                                                                      \n",
            "                                                                                                  \n",
            " conv2d_transpose_21 (Conv2  (None, 32, 32, 3)            6147      ['conv2d_transpose_20[0][0]'] \n",
            " DTranspose)                                                                                      \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 274755 (1.05 MB)\n",
            "Trainable params: 274755 (1.05 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2048 > 1024). Running this sequence through the model will result in indexing errors\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2284, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2284)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -2184 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2309, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2309)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -2209 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2151, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2151)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -2051 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2049, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2049)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1949 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 3056, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 3056)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -2956 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2049, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2049)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1949 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2433, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2433)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -2333 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2052, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2052)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1952 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2080, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2080)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1980 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2975, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2975)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -2875 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2231, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2231)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -2131 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2063, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2063)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1963 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2385, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2385)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -2285 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2125, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2125)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -2025 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2095, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2095)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1995 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 3554, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 3554)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -3454 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2502, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2502)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -2402 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2497, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2497)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -2397 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2193, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2193)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -2093 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2052, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2052)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1952 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2421, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2421)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -2321 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2081, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2081)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1981 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2063, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2063)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1963 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2054, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2054)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1954 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2241, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2241)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -2141 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2218, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2218)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -2118 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2051, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2051)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1951 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2049, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2049)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1949 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2404, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2404)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -2304 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2056, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2056)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1956 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2120, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2120)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -2020 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2056, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2056)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1956 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2051, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2051)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1951 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2093, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2093)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1993 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_22/kernel:0', 'conv2d_22/bias:0', 'conv2d_23/kernel:0', 'conv2d_23/bias:0', 'conv2d_transpose_20/kernel:0', 'conv2d_transpose_20/bias:0', 'conv2d_transpose_21/kernel:0', 'conv2d_transpose_21/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Input length of input_ids is 2048, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing`max_new_tokens`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens shape: (1, 2048)\n",
            "Error during token generation: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimension -1948 must be >= 0 [Op:Fill] name: \n"
          ]
        }
      ]
    }
  ]
}