
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ab2e95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ba6a351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for dataset loading (using synthetic data for simplicity)\n",
    "def generate_synthetic_data(num_samples, grid_size=32):\n",
    "    return np.random.randint(0, 2, size=(num_samples, grid_size, grid_size, grid_size))\n",
    "\n",
    "# Example: Generate 1000 samples of 3D voxel grids\n",
    "X_train = generate_synthetic_data(1000)\n",
    "X_train = X_train.astype('float32')  # Normalize the data\n",
    "\n",
    "# Visualize a sample voxel grid\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.voxels(X_train[0], edgecolors='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1fb0e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder network\n",
    "def build_encoder(latent_dim=64, input_shape=(32, 32, 32, 1)):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv3D(32, 3, activation='relu', strides=2, padding='same')(inputs)\n",
    "    x = layers.Conv3D(64, 3, activation='relu', strides=2, padding='same')(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    \n",
    "    # Latent space (mean and variance)\n",
    "    z_mean = layers.Dense(latent_dim, name='z_mean')(x)\n",
    "    z_log_var = layers.Dense(latent_dim, name='z_log_var')(x)\n",
    "    \n",
    "    return models.Model(inputs, [z_mean, z_log_var])\n",
    "\n",
    "# Decoder network\n",
    "def build_decoder(latent_dim=64, output_shape=(32, 32, 32, 1)):\n",
    "    latent_inputs = layers.Input(shape=(latent_dim,))\n",
    "    x = layers.Dense(128, activation='relu')(latent_inputs)\n",
    "    x = layers.Dense(8 * 8 * 8 * 64, activation='relu')(x)\n",
    "    x = layers.Reshape((8, 8, 8, 64))(x)\n",
    "    x = layers.Conv3DTranspose(64, 3, activation='relu', strides=2, padding='same')(x)\n",
    "    x = layers.Conv3DTranspose(32, 3, activation='relu', strides=2, padding='same')(x)\n",
    "    x = layers.Conv3DTranspose(1, 3, activation='sigmoid', padding='same')(x)\n",
    "    \n",
    "    return models.Model(latent_inputs, x)\n",
    "\n",
    "# VAE Model combining Encoder and Decoder\n",
    "latent_dim = 64\n",
    "encoder = build_encoder(latent_dim)\n",
    "decoder = build_decoder(latent_dim)\n",
    "\n",
    "# Sampling function for reparameterization trick\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch = tf.shape(z_mean)[0]\n",
    "    dim = tf.shape(z_mean)[1]\n",
    "    epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "# Define the VAE model\n",
    "inputs = layers.Input(shape=(32, 32, 32, 1))\n",
    "z_mean, z_log_var = encoder(inputs)\n",
    "z = layers.Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "decoded = decoder(z)\n",
    "\n",
    "vae = models.Model(inputs, decoded)\n",
    "\n",
    "# Loss function: Reconstruction + KL Divergence\n",
    "def vae_loss(y_true, y_pred):\n",
    "    reconstruction_loss = tf.reduce_mean(tf.reduce_sum(tf.keras.losses.binary_crossentropy(y_true, y_pred), axis=(1, 2, 3)))\n",
    "    kl_loss = - 0.5 * tf.reduce_mean(tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=1))\n",
    "    return reconstruction_loss + kl_loss\n",
    "\n",
    "# Compile the model\n",
    "vae.compile(optimizer='adam', loss=vae_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b2bb270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the VAE\n",
    "vae.fit(X_train, X_train, epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbb4c3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and visualize new 3D objects\n",
    "def generate_3d_objects(decoder, latent_dim, num_samples=5):\n",
    "    z_samples = np.random.normal(size=(num_samples, latent_dim))\n",
    "    generated_3d_objects = decoder.predict(z_samples)\n",
    "    return generated_3d_objects\n",
    "\n",
    "# Generate and visualize new 3D objects\n",
    "generated_objects = generate_3d_objects(decoder, latent_dim)\n",
    "\n",
    "# Visualize the first generated object\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.voxels(generated_objects[0].reshape(32, 32, 32), edgecolors='k')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".ipynb",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
