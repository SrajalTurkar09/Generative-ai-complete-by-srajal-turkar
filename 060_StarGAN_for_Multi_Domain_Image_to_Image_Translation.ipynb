{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf  # TensorFlow for building and training the neural networks\n",
        "from tensorflow.keras import layers, Model  # Layers and Model for modular design\n",
        "import numpy as np  # NumPy for numerical operations\n",
        "import matplotlib.pyplot as plt  # For visualizing results\n"
      ],
      "metadata": {
        "id": "gvlBY3hpQyrK"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load CIFAR-10 data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalize the images to [-1, 1] range\n",
        "x_train = (x_train / 127.5) - 1.0  # Normalize to [-1, 1]\n",
        "x_test = (x_test / 127.5) - 1.0\n",
        "\n",
        "# Resize images to (128, 128) for better resolution (optional)\n",
        "x_train = tf.image.resize(x_train, (128, 128))\n",
        "x_test = tf.image.resize(x_test, (128, 128))\n",
        "\n",
        "# Check dataset shape\n",
        "print(f\"x_train shape: {x_train.shape}\")\n"
      ],
      "metadata": {
        "id": "tldj9df-Q85B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c11Pt93tVB5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_one_hot = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test_one_hot = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "# Check label shape\n",
        "print(f\"y_train shape: {y_train_one_hot.shape}\")\n"
      ],
      "metadata": {
        "id": "HN7PbDY0R4wP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Define Generator\n",
        "class Generator(tf.keras.Model):\n",
        "    def __init__(self, num_domains):\n",
        "        super(Generator, self).__init__()\n",
        "        self.num_domains = num_domains\n",
        "        self.encoder = tf.keras.Sequential([\n",
        "            layers.InputLayer(input_shape=(128, 128, 3)),\n",
        "            layers.Conv2D(64, 4, 2, padding=\"same\", activation=\"relu\"),\n",
        "            layers.Conv2D(128, 4, 2, padding=\"same\", activation=\"relu\"),\n",
        "            layers.Conv2D(256, 4, 2, padding=\"same\", activation=\"relu\"),\n",
        "            layers.Conv2D(512, 4, 2, padding=\"same\", activation=\"relu\")\n",
        "        ])\n",
        "        self.fc = layers.Dense(512, activation=\"relu\")\n",
        "        self.decoder = tf.keras.Sequential([\n",
        "            layers.Conv2DTranspose(512, 4, 2, padding=\"same\", activation=\"relu\"),\n",
        "            layers.Conv2DTranspose(256, 4, 2, padding=\"same\", activation=\"relu\"),\n",
        "            layers.Conv2DTranspose(128, 4, 2, padding=\"same\", activation=\"relu\"),\n",
        "            layers.Conv2DTranspose(64, 4, 2, padding=\"same\", activation=\"relu\"),\n",
        "            layers.Conv2D(3, 3, 1, padding=\"same\", activation=\"tanh\")  # Final output layer\n",
        "        ])\n",
        "\n",
        "    def call(self, input_image, domain_label):\n",
        "        x = self.encoder(input_image)\n",
        "        x = self.fc(x)\n",
        "        x = tf.concat([x, domain_label], axis=-1)  # Concatenate domain label\n",
        "        generated_image = self.decoder(x)\n",
        "        return generated_image\n",
        "\n",
        "# Define Discriminator\n",
        "class Discriminator(tf.keras.Model):\n",
        "    def __init__(self, num_domains):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.num_domains = num_domains\n",
        "        self.model = tf.keras.Sequential([\n",
        "            layers.InputLayer(input_shape=(128, 128, 3)),\n",
        "            layers.Conv2D(64, 4, 2, padding=\"same\", activation=\"relu\"),\n",
        "            layers.Conv2D(128, 4, 2, padding=\"same\", activation=\"relu\"),\n",
        "            layers.Conv2D(256, 4, 2, padding=\"same\", activation=\"relu\"),\n",
        "            layers.Conv2D(512, 4, 2, padding=\"same\", activation=\"relu\"),\n",
        "            layers.Flatten(),\n",
        "            layers.Dense(1, activation=\"sigmoid\")  # Output real/fake score\n",
        "        ])\n",
        "\n",
        "    def call(self, input_image):\n",
        "        return self.model(input_image)\n",
        "\n",
        "# Instantiate models\n",
        "num_domains = 10  # 10 classes in CIFAR-10\n",
        "generator = Generator(num_domains)\n",
        "discriminator = Discriminator(num_domains)\n"
      ],
      "metadata": {
        "id": "suCralPyR5qa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adversarial loss (Binary Cross Entropy)\n",
        "adversarial_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "# Domain classification loss (Categorical Crossentropy)\n",
        "classification_loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "# L1 loss (for image reconstruction)\n",
        "l1_loss = tf.keras.losses.MeanAbsoluteError()\n"
      ],
      "metadata": {
        "id": "DSRe2T6UR8Eo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimizers\n",
        "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.5)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.5)\n",
        "\n",
        "@tf.function\n",
        "def train_step(real_images, domain_labels):\n",
        "    # Generate fake images\n",
        "    fake_images = generator(real_images, domain_labels)\n",
        "\n",
        "    # Discriminator loss\n",
        "    real_output = discriminator(real_images)\n",
        "    fake_output = discriminator(fake_images)\n",
        "    real_labels = tf.ones_like(real_output)\n",
        "    fake_labels = tf.zeros_like(fake_output)\n",
        "\n",
        "    d_loss_real = adversarial_loss(real_labels, real_output)\n",
        "    d_loss_fake = adversarial_loss(fake_labels, fake_output)\n",
        "    d_loss = d_loss_real + d_loss_fake\n",
        "\n",
        "    # Generator loss\n",
        "    g_loss = adversarial_loss(real_labels, fake_output) + classification_loss(domain_labels, fake_images)\n",
        "\n",
        "    # Backpropagation\n",
        "    gradients_of_generator = tf.gradients(g_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = tf.gradients(d_loss, discriminator.trainable_variables)\n",
        "\n",
        "    # Update weights\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "    return g_loss, d_loss\n"
      ],
      "metadata": {
        "id": "7d8AUL9bR9w1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_image(input_image, target_domain_label):\n",
        "    generated_image = generator(input_image, target_domain_label)\n",
        "    return generated_image\n"
      ],
      "metadata": {
        "id": "0v60kIg_R_Uz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    for batch in range(total_batches):\n",
        "        real_images, domain_labels = next_batch()  # Your batch loading logic here\n",
        "        g_loss, d_loss = train_step(real_images, domain_labels)\n",
        "\n",
        "    print(f\"Epoch {epoch}, Generator Loss: {g_loss}, Discriminator Loss: {d_loss}\")\n"
      ],
      "metadata": {
        "id": "Opnjk183Sd7W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}